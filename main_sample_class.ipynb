{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c70773-809f-470a-a9a4-b5907273e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import seaborn as sns; sns.set_theme()\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "from matplotlib.pyplot import figure\n",
    "from IPython import display\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import umap\n",
    "from sklearn import svm\n",
    "from lightgbm import LGBMClassifier\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a475f5-7b98-40da-be68-1770720796a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9614e-73b8-4b4d-8ab0-7a7ca7ab07d1",
   "metadata": {},
   "source": [
    "Load train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e7a64-bad8-4cf8-8ad0-00cd3ccf1f8b",
   "metadata": {},
   "source": [
    "# 1. Load data and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75a9ad-7160-472c-9860-cd8b46ba1ac2",
   "metadata": {},
   "source": [
    "## 1.1 Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5f81e6-1e1c-4e7a-b3b3-9adfaa705711",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./MLR_Project_train.csv')\n",
    "test = pd.read_csv('./MLR_Project_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f0ca5-9892-4287-8e9d-41a273c0e932",
   "metadata": {},
   "source": [
    "Show the data format and dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d204a102-98ba-4502-bc62-b2219ccbba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5874.524387</td>\n",
       "      <td>1072.671848</td>\n",
       "      <td>41440.76212</td>\n",
       "      <td>41440.23732</td>\n",
       "      <td>70.405148</td>\n",
       "      <td>7.392780</td>\n",
       "      <td>70.377281</td>\n",
       "      <td>23229.69262</td>\n",
       "      <td>23229.72655</td>\n",
       "      <td>70.378864</td>\n",
       "      <td>7.389173</td>\n",
       "      <td>70.380160</td>\n",
       "      <td>23229.76782</td>\n",
       "      <td>23379.81637</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>11.615135</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>23466.72590</td>\n",
       "      <td>23466.7259</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>7.425618</td>\n",
       "      <td>70.494241</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>4898.757333</td>\n",
       "      <td>15165.92759</td>\n",
       "      <td>297487.1654</td>\n",
       "      <td>297487.16540</td>\n",
       "      <td>15165.92759</td>\n",
       "      <td>4898.757333</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>64.192982</td>\n",
       "      <td>20.940618</td>\n",
       "      <td>76.070270</td>\n",
       "      <td>23376.73707</td>\n",
       "      <td>23343.13291</td>\n",
       "      <td>77.290965</td>\n",
       "      <td>347.308164</td>\n",
       "      <td>102.380501</td>\n",
       "      <td>24823.08137</td>\n",
       "      <td>24120.94894</td>\n",
       "      <td>332.757607</td>\n",
       "      <td>17.386711</td>\n",
       "      <td>129.622187</td>\n",
       "      <td>23936.99077</td>\n",
       "      <td>21670.19233</td>\n",
       "      <td>71.518948</td>\n",
       "      <td>11.399004</td>\n",
       "      <td>78.006816</td>\n",
       "      <td>26437.161240</td>\n",
       "      <td>23811.09670</td>\n",
       "      <td>141.997532</td>\n",
       "      <td>22.474794</td>\n",
       "      <td>0.013314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6124.154099</td>\n",
       "      <td>1072.802927</td>\n",
       "      <td>41440.76212</td>\n",
       "      <td>41442.22458</td>\n",
       "      <td>70.456758</td>\n",
       "      <td>7.356050</td>\n",
       "      <td>70.379576</td>\n",
       "      <td>23229.76020</td>\n",
       "      <td>23230.10472</td>\n",
       "      <td>70.273618</td>\n",
       "      <td>7.389813</td>\n",
       "      <td>70.329906</td>\n",
       "      <td>23229.46908</td>\n",
       "      <td>23384.98219</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>11.615135</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>23466.72590</td>\n",
       "      <td>23466.7259</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>7.441223</td>\n",
       "      <td>70.702624</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>5100.350569</td>\n",
       "      <td>15788.07683</td>\n",
       "      <td>308790.4312</td>\n",
       "      <td>308790.43120</td>\n",
       "      <td>15788.07683</td>\n",
       "      <td>5100.350569</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>2.937218</td>\n",
       "      <td>-14.428210</td>\n",
       "      <td>75.204973</td>\n",
       "      <td>23317.46049</td>\n",
       "      <td>23309.42032</td>\n",
       "      <td>74.880368</td>\n",
       "      <td>689.670872</td>\n",
       "      <td>127.070357</td>\n",
       "      <td>36746.26762</td>\n",
       "      <td>31012.79786</td>\n",
       "      <td>-310.576721</td>\n",
       "      <td>4.532673</td>\n",
       "      <td>-47.045260</td>\n",
       "      <td>22053.23653</td>\n",
       "      <td>14626.73339</td>\n",
       "      <td>48.124991</td>\n",
       "      <td>-99.618253</td>\n",
       "      <td>-115.120518</td>\n",
       "      <td>7705.543821</td>\n",
       "      <td>22665.35143</td>\n",
       "      <td>-377.287072</td>\n",
       "      <td>-73.700375</td>\n",
       "      <td>-0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5905.732593</td>\n",
       "      <td>1072.802927</td>\n",
       "      <td>41443.14358</td>\n",
       "      <td>41442.30403</td>\n",
       "      <td>70.422472</td>\n",
       "      <td>7.417794</td>\n",
       "      <td>70.376448</td>\n",
       "      <td>23229.48142</td>\n",
       "      <td>23229.61008</td>\n",
       "      <td>70.474265</td>\n",
       "      <td>7.388979</td>\n",
       "      <td>70.397301</td>\n",
       "      <td>23229.83396</td>\n",
       "      <td>23387.39168</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>11.615135</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>23466.72590</td>\n",
       "      <td>23466.7259</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>7.440201</td>\n",
       "      <td>70.686178</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>5308.548086</td>\n",
       "      <td>16430.60795</td>\n",
       "      <td>320463.9968</td>\n",
       "      <td>320463.99680</td>\n",
       "      <td>16430.60795</td>\n",
       "      <td>5308.548086</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>141.231442</td>\n",
       "      <td>25.855392</td>\n",
       "      <td>75.184756</td>\n",
       "      <td>23248.26780</td>\n",
       "      <td>23307.91084</td>\n",
       "      <td>74.635569</td>\n",
       "      <td>634.523047</td>\n",
       "      <td>71.705965</td>\n",
       "      <td>28917.00549</td>\n",
       "      <td>24632.17456</td>\n",
       "      <td>419.071308</td>\n",
       "      <td>7.403187</td>\n",
       "      <td>118.846496</td>\n",
       "      <td>23430.24573</td>\n",
       "      <td>31251.55292</td>\n",
       "      <td>71.535567</td>\n",
       "      <td>53.482719</td>\n",
       "      <td>106.179152</td>\n",
       "      <td>37586.677270</td>\n",
       "      <td>23251.62576</td>\n",
       "      <td>261.098973</td>\n",
       "      <td>22.565621</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6029.325221</td>\n",
       "      <td>1072.802927</td>\n",
       "      <td>41440.76212</td>\n",
       "      <td>41442.25682</td>\n",
       "      <td>70.458533</td>\n",
       "      <td>7.366031</td>\n",
       "      <td>70.379221</td>\n",
       "      <td>23230.08433</td>\n",
       "      <td>23229.87971</td>\n",
       "      <td>70.288944</td>\n",
       "      <td>7.390120</td>\n",
       "      <td>70.370247</td>\n",
       "      <td>23229.81662</td>\n",
       "      <td>23390.02296</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>11.615135</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23466.7259</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>7.439191</td>\n",
       "      <td>70.692085</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>5510.265781</td>\n",
       "      <td>17053.14128</td>\n",
       "      <td>331774.2409</td>\n",
       "      <td>75710.89648</td>\n",
       "      <td>17053.14128</td>\n",
       "      <td>5510.265781</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>-1.580478</td>\n",
       "      <td>-7.499746</td>\n",
       "      <td>75.184756</td>\n",
       "      <td>23248.26836</td>\n",
       "      <td>23307.91084</td>\n",
       "      <td>74.635569</td>\n",
       "      <td>583.001082</td>\n",
       "      <td>70.384022</td>\n",
       "      <td>25642.94219</td>\n",
       "      <td>23482.26269</td>\n",
       "      <td>-249.671869</td>\n",
       "      <td>7.388974</td>\n",
       "      <td>49.809681</td>\n",
       "      <td>23193.67720</td>\n",
       "      <td>15867.01579</td>\n",
       "      <td>70.369496</td>\n",
       "      <td>-12.169114</td>\n",
       "      <td>63.930236</td>\n",
       "      <td>10052.351290</td>\n",
       "      <td>23229.64352</td>\n",
       "      <td>-10.549985</td>\n",
       "      <td>4.656636</td>\n",
       "      <td>-0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6142.360146</td>\n",
       "      <td>1072.802927</td>\n",
       "      <td>41443.14358</td>\n",
       "      <td>41442.46480</td>\n",
       "      <td>70.413623</td>\n",
       "      <td>7.411287</td>\n",
       "      <td>70.376788</td>\n",
       "      <td>23229.70975</td>\n",
       "      <td>23229.82255</td>\n",
       "      <td>70.467206</td>\n",
       "      <td>7.389910</td>\n",
       "      <td>70.386986</td>\n",
       "      <td>23229.87603</td>\n",
       "      <td>23392.66710</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>11.615135</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>23466.72590</td>\n",
       "      <td>23466.7259</td>\n",
       "      <td>83.418623</td>\n",
       "      <td>7.438244</td>\n",
       "      <td>70.680386</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>1152.667997</td>\n",
       "      <td>17699.01445</td>\n",
       "      <td>343508.5253</td>\n",
       "      <td>343508.52530</td>\n",
       "      <td>17699.01445</td>\n",
       "      <td>5719.546213</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>149.144800</td>\n",
       "      <td>26.789196</td>\n",
       "      <td>74.904988</td>\n",
       "      <td>23229.77108</td>\n",
       "      <td>23260.32245</td>\n",
       "      <td>70.506980</td>\n",
       "      <td>566.549008</td>\n",
       "      <td>120.694073</td>\n",
       "      <td>25765.82131</td>\n",
       "      <td>24618.79392</td>\n",
       "      <td>363.188022</td>\n",
       "      <td>7.389057</td>\n",
       "      <td>78.826922</td>\n",
       "      <td>23235.86490</td>\n",
       "      <td>31790.06425</td>\n",
       "      <td>120.694068</td>\n",
       "      <td>42.971377</td>\n",
       "      <td>145.572170</td>\n",
       "      <td>37109.895810</td>\n",
       "      <td>24143.94971</td>\n",
       "      <td>188.639704</td>\n",
       "      <td>31.863254</td>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            0            1            2            3          4  \\\n",
       "0           0  5874.524387  1072.671848  41440.76212  41440.23732  70.405148   \n",
       "1           1  6124.154099  1072.802927  41440.76212  41442.22458  70.456758   \n",
       "2           2  5905.732593  1072.802927  41443.14358  41442.30403  70.422472   \n",
       "3           3  6029.325221  1072.802927  41440.76212  41442.25682  70.458533   \n",
       "4           4  6142.360146  1072.802927  41443.14358  41442.46480  70.413623   \n",
       "\n",
       "          5          6            7            8          9        10  \\\n",
       "0  7.392780  70.377281  23229.69262  23229.72655  70.378864  7.389173   \n",
       "1  7.356050  70.379576  23229.76020  23230.10472  70.273618  7.389813   \n",
       "2  7.417794  70.376448  23229.48142  23229.61008  70.474265  7.388979   \n",
       "3  7.366031  70.379221  23230.08433  23229.87971  70.288944  7.390120   \n",
       "4  7.411287  70.376788  23229.70975  23229.82255  70.467206  7.389910   \n",
       "\n",
       "          11           12           13         14         15         16  \\\n",
       "0  70.380160  23229.76782  23379.81637  83.418623  11.615135  83.418623   \n",
       "1  70.329906  23229.46908  23384.98219  83.418623  11.615135  83.418623   \n",
       "2  70.397301  23229.83396  23387.39168  83.418623  11.615135  83.418623   \n",
       "3  70.370247  23229.81662  23390.02296  83.418623  11.615135  83.418623   \n",
       "4  70.386986  23229.87603  23392.66710  70.572881  11.615135  83.418623   \n",
       "\n",
       "            17          18         19        20         21           22  \\\n",
       "0  23466.72590  23466.7259  83.418623  7.425618  70.494241  23229.77107   \n",
       "1  23466.72590  23466.7259  83.418623  7.441223  70.702624  23229.77107   \n",
       "2  23466.72590  23466.7259  83.418623  7.440201  70.686178  23229.77107   \n",
       "3  23233.34325  23466.7259  83.418623  7.439191  70.692085  23229.77107   \n",
       "4  23466.72590  23466.7259  83.418623  7.438244  70.680386  23229.77107   \n",
       "\n",
       "            23         24        25         26           27           28  \\\n",
       "0  23229.77107  70.376262  7.389056  70.376262  23229.77107  23229.77107   \n",
       "1  23229.77107  70.376262  7.389056  70.376262  23229.77107  23229.77107   \n",
       "2  23229.77107  70.376262  7.389056  70.376262  23229.77107  23229.77107   \n",
       "3  23229.77107  70.376262  7.389056  70.376262  23229.77107  23229.77107   \n",
       "4  23229.77107  70.376262  7.389056  70.376262  23229.77107  23229.77107   \n",
       "\n",
       "          29           30           31           32            33  \\\n",
       "0  70.376262  4898.757333  15165.92759  297487.1654  297487.16540   \n",
       "1  70.376262  5100.350569  15788.07683  308790.4312  308790.43120   \n",
       "2  70.376262  5308.548086  16430.60795  320463.9968  320463.99680   \n",
       "3  70.376262  5510.265781  17053.14128  331774.2409   75710.89648   \n",
       "4  70.376262  1152.667997  17699.01445  343508.5253  343508.52530   \n",
       "\n",
       "            34           35         36           37           38         39  \\\n",
       "0  15165.92759  4898.757333  70.376262  23229.77107  23229.77107  70.376262   \n",
       "1  15788.07683  5100.350569  70.376262  23229.77107  23229.77107  70.376262   \n",
       "2  16430.60795  5308.548086  70.376262  23229.77107  23229.77107  70.376262   \n",
       "3  17053.14128  5510.265781  70.376262  23229.77107  23229.77107  70.376262   \n",
       "4  17699.01445  5719.546213  70.376262  23229.77107  23229.77107  70.376262   \n",
       "\n",
       "         40         41           42           43          44         45  \\\n",
       "0  7.389056  70.376262  23229.77107  23229.77107   64.192982  20.940618   \n",
       "1  7.389056  70.376262  23229.77107  23229.77107    2.937218 -14.428210   \n",
       "2  7.389056  70.376262  23229.77107  23229.77107  141.231442  25.855392   \n",
       "3  7.389056  70.376262  23229.77107  23229.77107   -1.580478  -7.499746   \n",
       "4  7.389056  70.376262  23229.77107  23229.77107  149.144800  26.789196   \n",
       "\n",
       "          46           47           48         49          50          51  \\\n",
       "0  76.070270  23376.73707  23343.13291  77.290965  347.308164  102.380501   \n",
       "1  75.204973  23317.46049  23309.42032  74.880368  689.670872  127.070357   \n",
       "2  75.184756  23248.26780  23307.91084  74.635569  634.523047   71.705965   \n",
       "3  75.184756  23248.26836  23307.91084  74.635569  583.001082   70.384022   \n",
       "4  74.904988  23229.77108  23260.32245  70.506980  566.549008  120.694073   \n",
       "\n",
       "            52           53          54         55          56           57  \\\n",
       "0  24823.08137  24120.94894  332.757607  17.386711  129.622187  23936.99077   \n",
       "1  36746.26762  31012.79786 -310.576721   4.532673  -47.045260  22053.23653   \n",
       "2  28917.00549  24632.17456  419.071308   7.403187  118.846496  23430.24573   \n",
       "3  25642.94219  23482.26269 -249.671869   7.388974   49.809681  23193.67720   \n",
       "4  25765.82131  24618.79392  363.188022   7.389057   78.826922  23235.86490   \n",
       "\n",
       "            58          59         60          61            62           63  \\\n",
       "0  21670.19233   71.518948  11.399004   78.006816  26437.161240  23811.09670   \n",
       "1  14626.73339   48.124991 -99.618253 -115.120518   7705.543821  22665.35143   \n",
       "2  31251.55292   71.535567  53.482719  106.179152  37586.677270  23251.62576   \n",
       "3  15867.01579   70.369496 -12.169114   63.930236  10052.351290  23229.64352   \n",
       "4  31790.06425  120.694068  42.971377  145.572170  37109.895810  24143.94971   \n",
       "\n",
       "           64         65    TARGET  \n",
       "0  141.997532  22.474794  0.013314  \n",
       "1 -377.287072 -73.700375 -0.000448  \n",
       "2  261.098973  22.565621  0.000244  \n",
       "3  -10.549985   4.656636 -0.000628  \n",
       "4  188.639704  31.863254  0.003811  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b677e07a-0a62-4e5f-921b-89861aa36a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16335.49448</td>\n",
       "      <td>1061.530132</td>\n",
       "      <td>41238.33840</td>\n",
       "      <td>41237.30921</td>\n",
       "      <td>70.432910</td>\n",
       "      <td>7.379175</td>\n",
       "      <td>70.376460</td>\n",
       "      <td>23229.86828</td>\n",
       "      <td>23229.78910</td>\n",
       "      <td>70.397639</td>\n",
       "      <td>7.389850</td>\n",
       "      <td>70.389234</td>\n",
       "      <td>23229.90881</td>\n",
       "      <td>25602.51370</td>\n",
       "      <td>70.835039</td>\n",
       "      <td>7.537712</td>\n",
       "      <td>70.835039</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>70.703960</td>\n",
       "      <td>7.467846</td>\n",
       "      <td>70.433077</td>\n",
       "      <td>23230.96180</td>\n",
       "      <td>23278.59091</td>\n",
       "      <td>70.835039</td>\n",
       "      <td>7.537712</td>\n",
       "      <td>70.441802</td>\n",
       "      <td>23238.10616</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>70.703960</td>\n",
       "      <td>7133.700113</td>\n",
       "      <td>22063.32144</td>\n",
       "      <td>422799.6647</td>\n",
       "      <td>232518.5574</td>\n",
       "      <td>11589.95489</td>\n",
       "      <td>3740.045136</td>\n",
       "      <td>1860.710635</td>\n",
       "      <td>4138543.879</td>\n",
       "      <td>422799.6647</td>\n",
       "      <td>22063.32144</td>\n",
       "      <td>137.249904</td>\n",
       "      <td>66395.12033</td>\n",
       "      <td>232518.5574</td>\n",
       "      <td>232518.5574</td>\n",
       "      <td>258.079242</td>\n",
       "      <td>30.226219</td>\n",
       "      <td>75.913405</td>\n",
       "      <td>23229.77107</td>\n",
       "      <td>23229.83301</td>\n",
       "      <td>70.376262</td>\n",
       "      <td>1473.581679</td>\n",
       "      <td>71.758838</td>\n",
       "      <td>23874.69807</td>\n",
       "      <td>23499.73762</td>\n",
       "      <td>-155.498907</td>\n",
       "      <td>7.389056</td>\n",
       "      <td>70.371005</td>\n",
       "      <td>23229.77106</td>\n",
       "      <td>12139.388420</td>\n",
       "      <td>71.758829</td>\n",
       "      <td>14.703740</td>\n",
       "      <td>84.826620</td>\n",
       "      <td>8035.667142</td>\n",
       "      <td>23254.88967</td>\n",
       "      <td>92.945298</td>\n",
       "      <td>12.071364</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13166.20458</td>\n",
       "      <td>1061.661211</td>\n",
       "      <td>41238.33840</td>\n",
       "      <td>41238.66844</td>\n",
       "      <td>70.394428</td>\n",
       "      <td>7.378583</td>\n",
       "      <td>70.391576</td>\n",
       "      <td>23229.87463</td>\n",
       "      <td>23230.21191</td>\n",
       "      <td>70.288403</td>\n",
       "      <td>7.392921</td>\n",
       "      <td>70.343310</td>\n",
       "      <td>23229.64193</td>\n",
       "      <td>25607.58558</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.452766</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>23240.48762</td>\n",
       "      <td>23240.48762</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>7.469469</td>\n",
       "      <td>70.576552</td>\n",
       "      <td>23230.96180</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.452766</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>23280.97236</td>\n",
       "      <td>23240.48762</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>3945.011279</td>\n",
       "      <td>12222.51346</td>\n",
       "      <td>244010.9410</td>\n",
       "      <td>434292.0482</td>\n",
       "      <td>22695.88002</td>\n",
       "      <td>7338.666257</td>\n",
       "      <td>139.167102</td>\n",
       "      <td>1239716.334</td>\n",
       "      <td>244010.9410</td>\n",
       "      <td>12222.51346</td>\n",
       "      <td>792.472120</td>\n",
       "      <td>227216.19080</td>\n",
       "      <td>434292.0482</td>\n",
       "      <td>434292.0482</td>\n",
       "      <td>-147.808334</td>\n",
       "      <td>-20.702534</td>\n",
       "      <td>76.035317</td>\n",
       "      <td>23313.93717</td>\n",
       "      <td>23332.97615</td>\n",
       "      <td>75.852147</td>\n",
       "      <td>1828.336140</td>\n",
       "      <td>140.129854</td>\n",
       "      <td>37438.79508</td>\n",
       "      <td>30329.40335</td>\n",
       "      <td>167.006374</td>\n",
       "      <td>16.564437</td>\n",
       "      <td>34.929416</td>\n",
       "      <td>23264.53239</td>\n",
       "      <td>39398.972520</td>\n",
       "      <td>84.750309</td>\n",
       "      <td>60.805885</td>\n",
       "      <td>155.880284</td>\n",
       "      <td>41154.557460</td>\n",
       "      <td>24005.38063</td>\n",
       "      <td>199.782364</td>\n",
       "      <td>35.714646</td>\n",
       "      <td>-0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12897.58082</td>\n",
       "      <td>1061.661211</td>\n",
       "      <td>41240.71985</td>\n",
       "      <td>41238.89069</td>\n",
       "      <td>70.476942</td>\n",
       "      <td>7.400935</td>\n",
       "      <td>70.375313</td>\n",
       "      <td>23229.84429</td>\n",
       "      <td>23229.89405</td>\n",
       "      <td>70.469979</td>\n",
       "      <td>7.391477</td>\n",
       "      <td>70.407134</td>\n",
       "      <td>23230.09254</td>\n",
       "      <td>25610.09095</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.580185</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.470161</td>\n",
       "      <td>70.605117</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23280.97236</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>7.580185</td>\n",
       "      <td>70.441802</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>995.797053</td>\n",
       "      <td>23323.37355</td>\n",
       "      <td>445692.4097</td>\n",
       "      <td>255411.3025</td>\n",
       "      <td>12850.00699</td>\n",
       "      <td>4148.336212</td>\n",
       "      <td>3120.762743</td>\n",
       "      <td>4161436.624</td>\n",
       "      <td>445692.4097</td>\n",
       "      <td>23323.37355</td>\n",
       "      <td>233.004088</td>\n",
       "      <td>67655.17244</td>\n",
       "      <td>255411.3025</td>\n",
       "      <td>255411.3025</td>\n",
       "      <td>289.867668</td>\n",
       "      <td>32.185249</td>\n",
       "      <td>75.966899</td>\n",
       "      <td>23326.54724</td>\n",
       "      <td>23327.60253</td>\n",
       "      <td>75.649862</td>\n",
       "      <td>1924.171252</td>\n",
       "      <td>111.147939</td>\n",
       "      <td>37691.96604</td>\n",
       "      <td>29511.34868</td>\n",
       "      <td>53.482595</td>\n",
       "      <td>13.727445</td>\n",
       "      <td>165.790143</td>\n",
       "      <td>24499.54560</td>\n",
       "      <td>7180.863302</td>\n",
       "      <td>74.919427</td>\n",
       "      <td>-22.153780</td>\n",
       "      <td>54.137349</td>\n",
       "      <td>6873.937564</td>\n",
       "      <td>23667.70306</td>\n",
       "      <td>74.616186</td>\n",
       "      <td>24.773579</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12887.42863</td>\n",
       "      <td>1061.661211</td>\n",
       "      <td>41238.33840</td>\n",
       "      <td>41239.00250</td>\n",
       "      <td>70.412815</td>\n",
       "      <td>7.378490</td>\n",
       "      <td>70.377339</td>\n",
       "      <td>23229.91979</td>\n",
       "      <td>23229.86689</td>\n",
       "      <td>70.283757</td>\n",
       "      <td>7.389189</td>\n",
       "      <td>70.359007</td>\n",
       "      <td>23229.67957</td>\n",
       "      <td>25612.79171</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.452766</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23240.48762</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>7.469667</td>\n",
       "      <td>70.602493</td>\n",
       "      <td>23230.96180</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.452766</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>23280.97236</td>\n",
       "      <td>23240.48762</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>4329.804019</td>\n",
       "      <td>13410.04591</td>\n",
       "      <td>265586.1421</td>\n",
       "      <td>88824.3188</td>\n",
       "      <td>23883.41247</td>\n",
       "      <td>7723.458997</td>\n",
       "      <td>1326.699554</td>\n",
       "      <td>1261291.535</td>\n",
       "      <td>265586.1421</td>\n",
       "      <td>13410.04591</td>\n",
       "      <td>1177.264861</td>\n",
       "      <td>228403.72320</td>\n",
       "      <td>455867.2494</td>\n",
       "      <td>455867.2494</td>\n",
       "      <td>-141.955445</td>\n",
       "      <td>-15.581110</td>\n",
       "      <td>75.883198</td>\n",
       "      <td>23230.50078</td>\n",
       "      <td>23310.57289</td>\n",
       "      <td>73.052689</td>\n",
       "      <td>1808.877007</td>\n",
       "      <td>123.263599</td>\n",
       "      <td>31327.33150</td>\n",
       "      <td>25876.72169</td>\n",
       "      <td>86.016065</td>\n",
       "      <td>7.327061</td>\n",
       "      <td>26.252334</td>\n",
       "      <td>22958.21980</td>\n",
       "      <td>39599.779840</td>\n",
       "      <td>122.820383</td>\n",
       "      <td>46.190366</td>\n",
       "      <td>145.600464</td>\n",
       "      <td>39883.925250</td>\n",
       "      <td>24179.10475</td>\n",
       "      <td>145.999434</td>\n",
       "      <td>26.920634</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11994.73779</td>\n",
       "      <td>1061.661211</td>\n",
       "      <td>41240.71985</td>\n",
       "      <td>41238.81077</td>\n",
       "      <td>70.481341</td>\n",
       "      <td>7.392913</td>\n",
       "      <td>70.385266</td>\n",
       "      <td>23229.57329</td>\n",
       "      <td>23229.79297</td>\n",
       "      <td>70.450114</td>\n",
       "      <td>7.390389</td>\n",
       "      <td>70.377065</td>\n",
       "      <td>23229.74335</td>\n",
       "      <td>25615.17798</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.580185</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>7.469671</td>\n",
       "      <td>70.607659</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>23280.97236</td>\n",
       "      <td>70.966118</td>\n",
       "      <td>7.580185</td>\n",
       "      <td>70.441802</td>\n",
       "      <td>23235.72471</td>\n",
       "      <td>23233.34325</td>\n",
       "      <td>70.572881</td>\n",
       "      <td>1408.908041</td>\n",
       "      <td>24598.30068</td>\n",
       "      <td>468855.4055</td>\n",
       "      <td>278574.2983</td>\n",
       "      <td>14124.93413</td>\n",
       "      <td>4561.447200</td>\n",
       "      <td>4395.689873</td>\n",
       "      <td>4184599.619</td>\n",
       "      <td>468855.4055</td>\n",
       "      <td>24598.30068</td>\n",
       "      <td>175.464314</td>\n",
       "      <td>68930.09957</td>\n",
       "      <td>278574.2983</td>\n",
       "      <td>278574.2983</td>\n",
       "      <td>276.189378</td>\n",
       "      <td>21.701184</td>\n",
       "      <td>76.055710</td>\n",
       "      <td>23354.81165</td>\n",
       "      <td>23345.67063</td>\n",
       "      <td>77.102636</td>\n",
       "      <td>1906.984098</td>\n",
       "      <td>598.329736</td>\n",
       "      <td>40066.97972</td>\n",
       "      <td>36345.65544</td>\n",
       "      <td>-605.228200</td>\n",
       "      <td>-132.958333</td>\n",
       "      <td>-529.575904</td>\n",
       "      <td>12869.21582</td>\n",
       "      <td>6244.418503</td>\n",
       "      <td>-23.787704</td>\n",
       "      <td>-46.168214</td>\n",
       "      <td>-57.984418</td>\n",
       "      <td>-6030.026819</td>\n",
       "      <td>13649.75983</td>\n",
       "      <td>-694.862277</td>\n",
       "      <td>-218.983324</td>\n",
       "      <td>-0.001462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            0            1            2            3          4  \\\n",
       "0           0  16335.49448  1061.530132  41238.33840  41237.30921  70.432910   \n",
       "1           1  13166.20458  1061.661211  41238.33840  41238.66844  70.394428   \n",
       "2           2  12897.58082  1061.661211  41240.71985  41238.89069  70.476942   \n",
       "3           3  12887.42863  1061.661211  41238.33840  41239.00250  70.412815   \n",
       "4           4  11994.73779  1061.661211  41240.71985  41238.81077  70.481341   \n",
       "\n",
       "          5          6            7            8          9        10  \\\n",
       "0  7.379175  70.376460  23229.86828  23229.78910  70.397639  7.389850   \n",
       "1  7.378583  70.391576  23229.87463  23230.21191  70.288403  7.392921   \n",
       "2  7.400935  70.375313  23229.84429  23229.89405  70.469979  7.391477   \n",
       "3  7.378490  70.377339  23229.91979  23229.86689  70.283757  7.389189   \n",
       "4  7.392913  70.385266  23229.57329  23229.79297  70.450114  7.390389   \n",
       "\n",
       "          11           12           13         14        15         16  \\\n",
       "0  70.389234  23229.90881  25602.51370  70.835039  7.537712  70.835039   \n",
       "1  70.343310  23229.64193  25607.58558  70.572881  7.452766  70.572881   \n",
       "2  70.407134  23230.09254  25610.09095  70.572881  7.580185  70.966118   \n",
       "3  70.359007  23229.67957  25612.79171  70.572881  7.452766  70.572881   \n",
       "4  70.377065  23229.74335  25615.17798  70.572881  7.580185  70.966118   \n",
       "\n",
       "            17           18         19        20         21           22  \\\n",
       "0  23235.72471  23235.72471  70.703960  7.467846  70.433077  23230.96180   \n",
       "1  23240.48762  23240.48762  70.966118  7.469469  70.576552  23230.96180   \n",
       "2  23233.34325  23233.34325  70.572881  7.470161  70.605117  23233.34325   \n",
       "3  23233.34325  23240.48762  70.966118  7.469667  70.602493  23230.96180   \n",
       "4  23233.34325  23233.34325  70.572881  7.469671  70.607659  23233.34325   \n",
       "\n",
       "            23         24        25         26           27           28  \\\n",
       "0  23278.59091  70.835039  7.537712  70.441802  23238.10616  23235.72471   \n",
       "1  23235.72471  70.572881  7.452766  70.572881  23280.97236  23240.48762   \n",
       "2  23280.97236  70.966118  7.580185  70.441802  23235.72471  23233.34325   \n",
       "3  23235.72471  70.572881  7.452766  70.572881  23280.97236  23240.48762   \n",
       "4  23280.97236  70.966118  7.580185  70.441802  23235.72471  23233.34325   \n",
       "\n",
       "          29           30           31           32           33           34  \\\n",
       "0  70.703960  7133.700113  22063.32144  422799.6647  232518.5574  11589.95489   \n",
       "1  70.966118  3945.011279  12222.51346  244010.9410  434292.0482  22695.88002   \n",
       "2  70.572881   995.797053  23323.37355  445692.4097  255411.3025  12850.00699   \n",
       "3  70.966118  4329.804019  13410.04591  265586.1421   88824.3188  23883.41247   \n",
       "4  70.572881  1408.908041  24598.30068  468855.4055  278574.2983  14124.93413   \n",
       "\n",
       "            35           36           37           38           39  \\\n",
       "0  3740.045136  1860.710635  4138543.879  422799.6647  22063.32144   \n",
       "1  7338.666257   139.167102  1239716.334  244010.9410  12222.51346   \n",
       "2  4148.336212  3120.762743  4161436.624  445692.4097  23323.37355   \n",
       "3  7723.458997  1326.699554  1261291.535  265586.1421  13410.04591   \n",
       "4  4561.447200  4395.689873  4184599.619  468855.4055  24598.30068   \n",
       "\n",
       "            40            41           42           43          44         45  \\\n",
       "0   137.249904   66395.12033  232518.5574  232518.5574  258.079242  30.226219   \n",
       "1   792.472120  227216.19080  434292.0482  434292.0482 -147.808334 -20.702534   \n",
       "2   233.004088   67655.17244  255411.3025  255411.3025  289.867668  32.185249   \n",
       "3  1177.264861  228403.72320  455867.2494  455867.2494 -141.955445 -15.581110   \n",
       "4   175.464314   68930.09957  278574.2983  278574.2983  276.189378  21.701184   \n",
       "\n",
       "          46           47           48         49           50          51  \\\n",
       "0  75.913405  23229.77107  23229.83301  70.376262  1473.581679   71.758838   \n",
       "1  76.035317  23313.93717  23332.97615  75.852147  1828.336140  140.129854   \n",
       "2  75.966899  23326.54724  23327.60253  75.649862  1924.171252  111.147939   \n",
       "3  75.883198  23230.50078  23310.57289  73.052689  1808.877007  123.263599   \n",
       "4  76.055710  23354.81165  23345.67063  77.102636  1906.984098  598.329736   \n",
       "\n",
       "            52           53          54          55          56           57  \\\n",
       "0  23874.69807  23499.73762 -155.498907    7.389056   70.371005  23229.77106   \n",
       "1  37438.79508  30329.40335  167.006374   16.564437   34.929416  23264.53239   \n",
       "2  37691.96604  29511.34868   53.482595   13.727445  165.790143  24499.54560   \n",
       "3  31327.33150  25876.72169   86.016065    7.327061   26.252334  22958.21980   \n",
       "4  40066.97972  36345.65544 -605.228200 -132.958333 -529.575904  12869.21582   \n",
       "\n",
       "             58          59         60          61            62           63  \\\n",
       "0  12139.388420   71.758829  14.703740   84.826620   8035.667142  23254.88967   \n",
       "1  39398.972520   84.750309  60.805885  155.880284  41154.557460  24005.38063   \n",
       "2   7180.863302   74.919427 -22.153780   54.137349   6873.937564  23667.70306   \n",
       "3  39599.779840  122.820383  46.190366  145.600464  39883.925250  24179.10475   \n",
       "4   6244.418503  -23.787704 -46.168214  -57.984418  -6030.026819  13649.75983   \n",
       "\n",
       "           64          65    TARGET  \n",
       "0   92.945298   12.071364  0.010438  \n",
       "1  199.782364   35.714646 -0.000532  \n",
       "2   74.616186   24.773579  0.000726  \n",
       "3  145.999434   26.920634  0.001459  \n",
       "4 -694.862277 -218.983324 -0.001462  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633b9c-bc40-4658-89a5-1cc495586703",
   "metadata": {},
   "source": [
    "## 1.2 Check whether Nan exist in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1761492b-ff79-4083-bcda-0303800fc2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nan exist either in training or testing dataset\n"
     ]
    }
   ],
   "source": [
    "train_sum = train.isnull().sum().sum()\n",
    "test_sum = test.isnull().sum().sum()\n",
    "\n",
    "if train_sum == 0 and test_sum == 0:\n",
    "    print('No Nan exist either in training or testing dataset')\n",
    "elif train_sum != 0 and test_sum == 0:\n",
    "    print('Nan exist in train dataset, no Nan exist in test dataset')\n",
    "elif train_sum == 0 and test_sum != 0:\n",
    "    print('No Nan exist in train dataset, Nan exist in test dataset')\n",
    "else:\n",
    "    print('Nan exist both in training and testing dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b0f25-fdff-4ce6-a2a4-26bc5f7336a0",
   "metadata": {},
   "source": [
    "## 1.3 Show the maximum return of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0404bc17-40e7-423f-87c3-a050e7fbd448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum return of training set: 195.6927566509\n",
      "Maximum return of testing set: 55.96225182400002\n"
     ]
    }
   ],
   "source": [
    "train_max = np.sum(train['TARGET'][train['TARGET']>0])\n",
    "test_max = np.sum(test['TARGET'][test['TARGET']>0])\n",
    "\n",
    "print('Maximum return of training set:', train_max)\n",
    "print('Maximum return of testing set:', test_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbf2b1-9cdc-476e-9975-8e12dcbdee2b",
   "metadata": {},
   "source": [
    "### 1.3.1 Remove the Unnamed columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb5b0f0-c09f-44ee-975c-8613c205ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[:, ~train.columns.str.contains('^Unnamed')]\n",
    "test = test.loc[:, ~test.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562744d-bf00-48c2-9489-bb3953b6f438",
   "metadata": {},
   "source": [
    "## 1.4 Naive random selection experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2bdc66-19b4-40cc-b27f-c676864e2863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of train naive random selection: -0.8275621056692822\n",
      "Result of test naive random selection: -0.6531676759990601\n"
     ]
    }
   ],
   "source": [
    "train_random = 0\n",
    "for j in range(10000):\n",
    "    ind = np.random.randint(2, size=train.shape[0])\n",
    "    train_random = train_random + sum(train['TARGET'][ind>0])\n",
    "\n",
    "print('Result of train naive random selection:', train_random/10000)\n",
    "\n",
    "test_random = 0\n",
    "for j in range(10000):\n",
    "    ind = np.random.randint(2, size=test.shape[0])\n",
    "    test_random = test_random + sum(test['TARGET'][ind>0])\n",
    "\n",
    "print('Result of test naive random selection:', test_random/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f271e7a5-ff2d-4e48-b332-1a91b3656b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train naive random selection percentage return: -0.4228884705965821%\n",
      "Test naive random selection percentage return: -1.167157601258179%\n"
     ]
    }
   ],
   "source": [
    "print(f'Train naive random selection percentage return: {train_random/train_max/100}%')\n",
    "print(f'Test naive random selection percentage return: {test_random/test_max/100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01fe714-f925-46d1-9702-3baee74a3729",
   "metadata": {},
   "source": [
    "## 1.5 Get data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c335643-2336-4593-a3ed-e48e4eec7046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (90000, 67)\n",
      "Test shape: (19707, 67)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51177e3-5eab-4917-a56f-86a76c413ee2",
   "metadata": {},
   "source": [
    "## 3.1 Remove extreme Target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a272254a-5bc3-4735-ac3b-27c14ac8f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['TARGET'])\n",
    "# remove samples with extreme large target values and samples with extreme negative values\n",
    "num_remove = 10\n",
    "train_remove = train.iloc[num_remove:-num_remove, :]\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e3f63-001d-4ef6-b4d7-688667fe377b",
   "metadata": {},
   "source": [
    "## 3.2 Remove extreme features values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ffdc30-d8ad-439f-9ec6-23632c274ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train.shape[1]-1):\n",
    "    train_remove = train_remove.sort_values(by=[str(i)])\n",
    "    num_remove = 5\n",
    "    train_remove = train_remove.iloc[num_remove:-num_remove, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "696e4faf-b945-45ee-ab9a-1d71e876d98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89320, 67)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_remove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f010d801-5d82-4c48-948b-1b83ba80e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = train_remove.iloc[:, 0:66].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623cc1c1-897f-4688-b797-7ec911190d8c",
   "metadata": {},
   "source": [
    "### 4.2 Analyze each feature variabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "717936d5-b7db-4666-90ea-6180f63efaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(1, 1, figsize = (35, 7))\n",
    "\n",
    "train_remove_mean_values = train_remove.mean()\n",
    "train_remove_std_values = train_remove.std()\n",
    "\n",
    "train_remove_std = (train_remove-train_remove.mean())/train_remove.std()\n",
    "\n",
    "train_remove_std.boxplot()\n",
    "ax.set_xlabel('Features', fontsize=20)\n",
    "ax.set_ylabel('Values', fontsize=20)\n",
    "ax.set_title('Train standardized features variability', fontsize=25)\n",
    "\n",
    "figure.savefig(\"features_std_dis.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c8fd75-41a0-41bb-bc59-1ff78a0c53ff",
   "metadata": {},
   "source": [
    "### The devil is in the details, we need to standardize test dataset by using train mean and train standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7497dc7a-2b83-4de8-bc95-09f24744f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_std = (test-train_remove_mean_values)/train_remove_std_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24330a67-b326-4f90-95b4-0d48bbe1a22c",
   "metadata": {},
   "source": [
    "## 4.3 Remove Multicollinearity among features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d4608d4-8ad8-4575-9c2b-5989732e0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_set = set()\n",
    "threshold = 0.95\n",
    "for i in range(66):\n",
    "    for j in range(i+1, 66):\n",
    "        if i not in remove_set and correlation_df.iloc[i, j] >=threshold:\n",
    "            remove_set.add(str(j))\n",
    "remove_set = list(remove_set)\n",
    "\n",
    "\n",
    "train_std_noncor = train_remove_std.drop(remove_set, axis=1)\n",
    "test_std_noncor = test_std.drop(remove_set, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f300883-8c2e-4d38-ae12-f1223573c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89320, 60)\n",
      "['0', '1', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '33', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65']\n"
     ]
    }
   ],
   "source": [
    "print(train_std_noncor.shape)\n",
    "non_cor_names = list(train_std_noncor.columns.values)\n",
    "# print(non_cor_names)\n",
    "non_cor_names.remove('TARGET')\n",
    "print(non_cor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "678fef76-9ea2-4a44-a090-8d42739a295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge regression\n",
      "Maximum sum train return 24.4603256455, Total train return: 195.6927566509, Maximum train percentage return: 12.499351567281172%\n",
      "Maximum sum test return 3.7559956681999997, Total test return: 55.96225182400002, Maximum test percentage return: 6.711659280638882%\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "# train\n",
    "reg = Ridge(alpha=0.04)\n",
    "reg.fit(train_std_noncor.iloc[:, 0:59], train_std_noncor.iloc[:, 59])\n",
    "\n",
    "pred = reg.predict(train_std_noncor.iloc[:, 0:59])\n",
    "\n",
    "# test\n",
    "pred_test = reg.predict(test_std_noncor.iloc[:, 0:59])\n",
    "\n",
    "train_res = np.sum(train_remove['TARGET'][pred>0])\n",
    "test_res = np.sum(test['TARGET'][pred_test>0])\n",
    "\n",
    "print()\n",
    "print('Ridge regression')\n",
    "print(f'Maximum sum train return {train_res}, Total train return: {train_max}, Maximum train percentage return: {train_res/train_max*100}%')\n",
    "print(f'Maximum sum test return {test_res}, Total test return: {test_max}, Maximum test percentage return: {test_res/test_max*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aea8f8-67bc-43a6-9f14-b0ed5a294b4c",
   "metadata": {},
   "source": [
    "### After removing high correlation features, model performance improved by using ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0936c7e-24f0-4f03-be1f-9ed8d844b381",
   "metadata": {},
   "source": [
    "## 5.3 Nonlinear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989a5a6-a0bf-4c50-bb13-24ab06694bab",
   "metadata": {},
   "source": [
    "### Conclusion: support vector machine method doesn't performa well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91132f5e-e1fc-4108-b2c0-ed422db1125f",
   "metadata": {},
   "source": [
    "## 5.5 Autoencoder Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e82ac411-23de-45a2-83ec-265f7eb7c213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15569</th>\n",
       "      <td>-1.591570</td>\n",
       "      <td>0.419550</td>\n",
       "      <td>0.409574</td>\n",
       "      <td>0.420952</td>\n",
       "      <td>0.344451</td>\n",
       "      <td>5.268275</td>\n",
       "      <td>-2.638600</td>\n",
       "      <td>0.867947</td>\n",
       "      <td>-0.958219</td>\n",
       "      <td>0.502489</td>\n",
       "      <td>-0.276027</td>\n",
       "      <td>2.705966</td>\n",
       "      <td>1.924548</td>\n",
       "      <td>1.011336</td>\n",
       "      <td>0.296421</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.212895</td>\n",
       "      <td>-0.112213</td>\n",
       "      <td>-0.023840</td>\n",
       "      <td>-0.177325</td>\n",
       "      <td>11.163422</td>\n",
       "      <td>4.744509</td>\n",
       "      <td>6.903074</td>\n",
       "      <td>2.952768</td>\n",
       "      <td>8.991375</td>\n",
       "      <td>6.239567</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>4.263071</td>\n",
       "      <td>3.636834</td>\n",
       "      <td>4.441104</td>\n",
       "      <td>-0.481989</td>\n",
       "      <td>-0.671017</td>\n",
       "      <td>-0.547252</td>\n",
       "      <td>-0.311373</td>\n",
       "      <td>0.116526</td>\n",
       "      <td>-0.375818</td>\n",
       "      <td>2.379025</td>\n",
       "      <td>-0.837720</td>\n",
       "      <td>-0.216616</td>\n",
       "      <td>-0.679874</td>\n",
       "      <td>-0.851833</td>\n",
       "      <td>1.441253</td>\n",
       "      <td>0.989817</td>\n",
       "      <td>1.782174</td>\n",
       "      <td>-0.442508</td>\n",
       "      <td>0.300462</td>\n",
       "      <td>0.861421</td>\n",
       "      <td>0.684658</td>\n",
       "      <td>0.862615</td>\n",
       "      <td>0.855227</td>\n",
       "      <td>6.053265</td>\n",
       "      <td>1.163374</td>\n",
       "      <td>3.210753</td>\n",
       "      <td>2.555351</td>\n",
       "      <td>0.597081</td>\n",
       "      <td>1.156251</td>\n",
       "      <td>3.101378</td>\n",
       "      <td>2.763801</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.877375</td>\n",
       "      <td>1.067262</td>\n",
       "      <td>1.468370</td>\n",
       "      <td>0.454987</td>\n",
       "      <td>1.632157</td>\n",
       "      <td>2.922553</td>\n",
       "      <td>2.837309</td>\n",
       "      <td>-10.046572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39228</th>\n",
       "      <td>1.657266</td>\n",
       "      <td>0.419550</td>\n",
       "      <td>0.429479</td>\n",
       "      <td>0.417079</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>-0.238355</td>\n",
       "      <td>-0.066295</td>\n",
       "      <td>0.398381</td>\n",
       "      <td>-0.351540</td>\n",
       "      <td>-0.109290</td>\n",
       "      <td>-0.039896</td>\n",
       "      <td>0.291888</td>\n",
       "      <td>0.187233</td>\n",
       "      <td>1.412469</td>\n",
       "      <td>-0.426931</td>\n",
       "      <td>-0.530180</td>\n",
       "      <td>-0.477976</td>\n",
       "      <td>-0.426767</td>\n",
       "      <td>-0.556078</td>\n",
       "      <td>-0.477765</td>\n",
       "      <td>-0.016130</td>\n",
       "      <td>0.131895</td>\n",
       "      <td>-0.646844</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>-0.483598</td>\n",
       "      <td>-0.053288</td>\n",
       "      <td>0.294614</td>\n",
       "      <td>-0.321377</td>\n",
       "      <td>-0.072252</td>\n",
       "      <td>-0.353769</td>\n",
       "      <td>-0.435937</td>\n",
       "      <td>-0.245459</td>\n",
       "      <td>-0.500976</td>\n",
       "      <td>-0.558643</td>\n",
       "      <td>-0.540297</td>\n",
       "      <td>-0.624276</td>\n",
       "      <td>-0.862643</td>\n",
       "      <td>0.654132</td>\n",
       "      <td>0.111164</td>\n",
       "      <td>0.818974</td>\n",
       "      <td>0.965010</td>\n",
       "      <td>0.528491</td>\n",
       "      <td>0.699632</td>\n",
       "      <td>-0.224033</td>\n",
       "      <td>0.265885</td>\n",
       "      <td>-1.017788</td>\n",
       "      <td>0.448340</td>\n",
       "      <td>1.252381</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.576805</td>\n",
       "      <td>-0.035673</td>\n",
       "      <td>-0.541829</td>\n",
       "      <td>-0.365109</td>\n",
       "      <td>-0.633775</td>\n",
       "      <td>1.312632</td>\n",
       "      <td>-0.010459</td>\n",
       "      <td>0.497131</td>\n",
       "      <td>0.078190</td>\n",
       "      <td>-0.438461</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.311147</td>\n",
       "      <td>0.217054</td>\n",
       "      <td>0.820794</td>\n",
       "      <td>-0.007006</td>\n",
       "      <td>0.520544</td>\n",
       "      <td>0.142942</td>\n",
       "      <td>-9.546656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63256</th>\n",
       "      <td>4.420895</td>\n",
       "      <td>-0.874390</td>\n",
       "      <td>-0.864394</td>\n",
       "      <td>-0.873736</td>\n",
       "      <td>-0.139562</td>\n",
       "      <td>-1.085084</td>\n",
       "      <td>0.529977</td>\n",
       "      <td>-1.422117</td>\n",
       "      <td>-0.051032</td>\n",
       "      <td>-2.512911</td>\n",
       "      <td>-0.879755</td>\n",
       "      <td>-2.558165</td>\n",
       "      <td>-2.110127</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>2.655177</td>\n",
       "      <td>2.022884</td>\n",
       "      <td>2.465737</td>\n",
       "      <td>-0.112213</td>\n",
       "      <td>-0.236735</td>\n",
       "      <td>-0.177325</td>\n",
       "      <td>0.549805</td>\n",
       "      <td>0.436038</td>\n",
       "      <td>-0.646844</td>\n",
       "      <td>-0.975802</td>\n",
       "      <td>-0.895553</td>\n",
       "      <td>-0.952267</td>\n",
       "      <td>2.176367</td>\n",
       "      <td>1.315925</td>\n",
       "      <td>3.636834</td>\n",
       "      <td>3.242385</td>\n",
       "      <td>2.916167</td>\n",
       "      <td>2.749283</td>\n",
       "      <td>2.867501</td>\n",
       "      <td>-0.275111</td>\n",
       "      <td>-0.054112</td>\n",
       "      <td>-0.339382</td>\n",
       "      <td>-0.849244</td>\n",
       "      <td>-0.929493</td>\n",
       "      <td>-1.037987</td>\n",
       "      <td>-1.088969</td>\n",
       "      <td>1.041170</td>\n",
       "      <td>-0.351585</td>\n",
       "      <td>1.247452</td>\n",
       "      <td>1.485541</td>\n",
       "      <td>-1.979334</td>\n",
       "      <td>-1.862797</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.652249</td>\n",
       "      <td>0.385049</td>\n",
       "      <td>0.546543</td>\n",
       "      <td>1.729638</td>\n",
       "      <td>0.092868</td>\n",
       "      <td>1.128907</td>\n",
       "      <td>1.094857</td>\n",
       "      <td>-2.484805</td>\n",
       "      <td>-0.933589</td>\n",
       "      <td>-4.515653</td>\n",
       "      <td>-3.661379</td>\n",
       "      <td>-2.859678</td>\n",
       "      <td>-0.459531</td>\n",
       "      <td>-2.769091</td>\n",
       "      <td>-2.158519</td>\n",
       "      <td>-3.062226</td>\n",
       "      <td>-0.963747</td>\n",
       "      <td>-4.707058</td>\n",
       "      <td>-3.834919</td>\n",
       "      <td>-9.106747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74827</th>\n",
       "      <td>-1.995347</td>\n",
       "      <td>-1.531313</td>\n",
       "      <td>-1.541189</td>\n",
       "      <td>-1.533136</td>\n",
       "      <td>-0.473125</td>\n",
       "      <td>-0.121628</td>\n",
       "      <td>-0.874190</td>\n",
       "      <td>-1.789493</td>\n",
       "      <td>-1.295655</td>\n",
       "      <td>0.880549</td>\n",
       "      <td>-1.454116</td>\n",
       "      <td>-1.161337</td>\n",
       "      <td>-1.467101</td>\n",
       "      <td>0.818498</td>\n",
       "      <td>-0.364031</td>\n",
       "      <td>-0.344019</td>\n",
       "      <td>-0.417900</td>\n",
       "      <td>-0.300946</td>\n",
       "      <td>-0.449630</td>\n",
       "      <td>-0.357589</td>\n",
       "      <td>1.056042</td>\n",
       "      <td>0.699015</td>\n",
       "      <td>0.296893</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>1.164224</td>\n",
       "      <td>2.044331</td>\n",
       "      <td>0.294614</td>\n",
       "      <td>0.497274</td>\n",
       "      <td>-0.484374</td>\n",
       "      <td>-0.653449</td>\n",
       "      <td>-0.514991</td>\n",
       "      <td>-0.218069</td>\n",
       "      <td>-0.580416</td>\n",
       "      <td>0.397065</td>\n",
       "      <td>0.459752</td>\n",
       "      <td>0.336021</td>\n",
       "      <td>2.334043</td>\n",
       "      <td>1.455653</td>\n",
       "      <td>1.286623</td>\n",
       "      <td>0.915443</td>\n",
       "      <td>-0.608926</td>\n",
       "      <td>0.542251</td>\n",
       "      <td>-1.002200</td>\n",
       "      <td>-1.071539</td>\n",
       "      <td>0.751532</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>0.264638</td>\n",
       "      <td>0.355586</td>\n",
       "      <td>-0.172777</td>\n",
       "      <td>-0.069807</td>\n",
       "      <td>1.238364</td>\n",
       "      <td>0.053652</td>\n",
       "      <td>0.684905</td>\n",
       "      <td>0.499513</td>\n",
       "      <td>1.283343</td>\n",
       "      <td>0.106117</td>\n",
       "      <td>0.730878</td>\n",
       "      <td>0.419319</td>\n",
       "      <td>2.151723</td>\n",
       "      <td>0.917287</td>\n",
       "      <td>1.351149</td>\n",
       "      <td>1.647902</td>\n",
       "      <td>1.857436</td>\n",
       "      <td>0.399532</td>\n",
       "      <td>1.097568</td>\n",
       "      <td>0.939363</td>\n",
       "      <td>-8.929755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18477</th>\n",
       "      <td>-0.747015</td>\n",
       "      <td>-0.237373</td>\n",
       "      <td>-0.247316</td>\n",
       "      <td>-0.238324</td>\n",
       "      <td>-0.243295</td>\n",
       "      <td>-3.914652</td>\n",
       "      <td>-1.016323</td>\n",
       "      <td>0.891080</td>\n",
       "      <td>-0.004867</td>\n",
       "      <td>-1.154787</td>\n",
       "      <td>-0.380911</td>\n",
       "      <td>-0.220514</td>\n",
       "      <td>0.044639</td>\n",
       "      <td>1.258196</td>\n",
       "      <td>0.233521</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>0.152820</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>-0.289959</td>\n",
       "      <td>-0.147281</td>\n",
       "      <td>9.270608</td>\n",
       "      <td>1.605086</td>\n",
       "      <td>-0.646844</td>\n",
       "      <td>2.625387</td>\n",
       "      <td>8.167465</td>\n",
       "      <td>5.640248</td>\n",
       "      <td>1.235490</td>\n",
       "      <td>0.988465</td>\n",
       "      <td>4.048954</td>\n",
       "      <td>2.643026</td>\n",
       "      <td>-0.218305</td>\n",
       "      <td>-0.405615</td>\n",
       "      <td>-0.282281</td>\n",
       "      <td>-0.440242</td>\n",
       "      <td>-0.628870</td>\n",
       "      <td>-0.505305</td>\n",
       "      <td>-0.839074</td>\n",
       "      <td>-0.628022</td>\n",
       "      <td>1.660188</td>\n",
       "      <td>0.254892</td>\n",
       "      <td>0.679757</td>\n",
       "      <td>-0.805067</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>-0.535480</td>\n",
       "      <td>1.281962</td>\n",
       "      <td>-1.043885</td>\n",
       "      <td>0.638068</td>\n",
       "      <td>1.469045</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>1.118936</td>\n",
       "      <td>4.856749</td>\n",
       "      <td>1.770205</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>1.041571</td>\n",
       "      <td>-1.251713</td>\n",
       "      <td>5.038597</td>\n",
       "      <td>0.616455</td>\n",
       "      <td>2.376650</td>\n",
       "      <td>2.432383</td>\n",
       "      <td>-0.368392</td>\n",
       "      <td>-0.208555</td>\n",
       "      <td>-0.441813</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>4.246476</td>\n",
       "      <td>0.424501</td>\n",
       "      <td>1.831210</td>\n",
       "      <td>-8.914202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61204</th>\n",
       "      <td>1.656962</td>\n",
       "      <td>-0.177653</td>\n",
       "      <td>-0.167693</td>\n",
       "      <td>-0.180926</td>\n",
       "      <td>0.821588</td>\n",
       "      <td>-0.252692</td>\n",
       "      <td>-1.339318</td>\n",
       "      <td>-0.663164</td>\n",
       "      <td>-0.930222</td>\n",
       "      <td>-0.377452</td>\n",
       "      <td>-1.118971</td>\n",
       "      <td>-0.536899</td>\n",
       "      <td>-0.713970</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>-0.426931</td>\n",
       "      <td>-0.583369</td>\n",
       "      <td>-0.477976</td>\n",
       "      <td>-0.426767</td>\n",
       "      <td>-0.502854</td>\n",
       "      <td>-0.477765</td>\n",
       "      <td>-0.358286</td>\n",
       "      <td>-1.410333</td>\n",
       "      <td>-0.646844</td>\n",
       "      <td>-0.648422</td>\n",
       "      <td>-0.483598</td>\n",
       "      <td>-0.352947</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>1.152195</td>\n",
       "      <td>-0.484374</td>\n",
       "      <td>0.245590</td>\n",
       "      <td>-0.372290</td>\n",
       "      <td>-0.560603</td>\n",
       "      <td>-0.437018</td>\n",
       "      <td>-0.503760</td>\n",
       "      <td>-0.304361</td>\n",
       "      <td>-0.569129</td>\n",
       "      <td>-0.862129</td>\n",
       "      <td>-0.281591</td>\n",
       "      <td>0.564179</td>\n",
       "      <td>1.799167</td>\n",
       "      <td>-0.852391</td>\n",
       "      <td>1.967940</td>\n",
       "      <td>-0.377056</td>\n",
       "      <td>0.605589</td>\n",
       "      <td>-0.437310</td>\n",
       "      <td>-1.181482</td>\n",
       "      <td>-2.303588</td>\n",
       "      <td>0.811427</td>\n",
       "      <td>-0.718607</td>\n",
       "      <td>0.095167</td>\n",
       "      <td>-0.690082</td>\n",
       "      <td>0.467158</td>\n",
       "      <td>-0.412690</td>\n",
       "      <td>-0.138718</td>\n",
       "      <td>-0.112264</td>\n",
       "      <td>-0.579451</td>\n",
       "      <td>-0.254788</td>\n",
       "      <td>-0.345010</td>\n",
       "      <td>-2.358189</td>\n",
       "      <td>-1.635336</td>\n",
       "      <td>-1.687696</td>\n",
       "      <td>-1.528272</td>\n",
       "      <td>-1.049639</td>\n",
       "      <td>-1.050762</td>\n",
       "      <td>-0.834965</td>\n",
       "      <td>-0.834457</td>\n",
       "      <td>8.679049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88401</th>\n",
       "      <td>-1.596186</td>\n",
       "      <td>-1.531313</td>\n",
       "      <td>-1.541189</td>\n",
       "      <td>-1.534059</td>\n",
       "      <td>-0.700698</td>\n",
       "      <td>0.754291</td>\n",
       "      <td>0.340029</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.444887</td>\n",
       "      <td>1.178909</td>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.322184</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>0.814640</td>\n",
       "      <td>-0.364031</td>\n",
       "      <td>-0.503586</td>\n",
       "      <td>-0.417900</td>\n",
       "      <td>-0.363856</td>\n",
       "      <td>-0.502854</td>\n",
       "      <td>-0.417677</td>\n",
       "      <td>-0.369034</td>\n",
       "      <td>-0.256129</td>\n",
       "      <td>1.240635</td>\n",
       "      <td>0.497412</td>\n",
       "      <td>0.752268</td>\n",
       "      <td>0.246372</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>-0.321377</td>\n",
       "      <td>-0.896493</td>\n",
       "      <td>-0.953128</td>\n",
       "      <td>-0.512976</td>\n",
       "      <td>-0.451153</td>\n",
       "      <td>-0.578391</td>\n",
       "      <td>0.781976</td>\n",
       "      <td>0.815797</td>\n",
       "      <td>0.722780</td>\n",
       "      <td>1.872242</td>\n",
       "      <td>1.552998</td>\n",
       "      <td>1.338167</td>\n",
       "      <td>0.094505</td>\n",
       "      <td>-0.820758</td>\n",
       "      <td>0.334770</td>\n",
       "      <td>-1.033856</td>\n",
       "      <td>-1.087304</td>\n",
       "      <td>1.254948</td>\n",
       "      <td>0.698499</td>\n",
       "      <td>-0.060818</td>\n",
       "      <td>-0.205245</td>\n",
       "      <td>0.271961</td>\n",
       "      <td>0.435646</td>\n",
       "      <td>0.148935</td>\n",
       "      <td>-0.428325</td>\n",
       "      <td>-0.130954</td>\n",
       "      <td>-0.246770</td>\n",
       "      <td>1.124562</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.952169</td>\n",
       "      <td>0.604934</td>\n",
       "      <td>1.627698</td>\n",
       "      <td>0.158657</td>\n",
       "      <td>1.523564</td>\n",
       "      <td>0.916127</td>\n",
       "      <td>1.522226</td>\n",
       "      <td>0.113719</td>\n",
       "      <td>1.341889</td>\n",
       "      <td>0.833395</td>\n",
       "      <td>8.772971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25438</th>\n",
       "      <td>-0.263765</td>\n",
       "      <td>1.116287</td>\n",
       "      <td>1.126180</td>\n",
       "      <td>1.113323</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.539529</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.044383</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>-0.323590</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.138877</td>\n",
       "      <td>0.119234</td>\n",
       "      <td>0.367241</td>\n",
       "      <td>-0.426931</td>\n",
       "      <td>-0.583369</td>\n",
       "      <td>-0.477976</td>\n",
       "      <td>-0.332401</td>\n",
       "      <td>-0.423018</td>\n",
       "      <td>-0.387633</td>\n",
       "      <td>0.089186</td>\n",
       "      <td>-0.284689</td>\n",
       "      <td>0.296893</td>\n",
       "      <td>0.170030</td>\n",
       "      <td>-0.483598</td>\n",
       "      <td>-0.652607</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>0.661004</td>\n",
       "      <td>0.751989</td>\n",
       "      <td>1.144629</td>\n",
       "      <td>-0.561671</td>\n",
       "      <td>-0.751218</td>\n",
       "      <td>-0.627323</td>\n",
       "      <td>-0.364364</td>\n",
       "      <td>-0.054606</td>\n",
       "      <td>-0.429064</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.783761</td>\n",
       "      <td>-0.962348</td>\n",
       "      <td>-0.808549</td>\n",
       "      <td>1.146843</td>\n",
       "      <td>0.613324</td>\n",
       "      <td>1.483805</td>\n",
       "      <td>-0.795387</td>\n",
       "      <td>0.193299</td>\n",
       "      <td>-0.091760</td>\n",
       "      <td>-0.472319</td>\n",
       "      <td>0.051091</td>\n",
       "      <td>0.148756</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>-0.390475</td>\n",
       "      <td>-0.003853</td>\n",
       "      <td>-0.170826</td>\n",
       "      <td>-0.825931</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>-0.121071</td>\n",
       "      <td>-0.086152</td>\n",
       "      <td>-0.299082</td>\n",
       "      <td>0.685928</td>\n",
       "      <td>0.652316</td>\n",
       "      <td>0.825749</td>\n",
       "      <td>-0.751525</td>\n",
       "      <td>0.209183</td>\n",
       "      <td>0.143924</td>\n",
       "      <td>0.222764</td>\n",
       "      <td>8.879313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57638</th>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.439457</td>\n",
       "      <td>0.449385</td>\n",
       "      <td>0.443070</td>\n",
       "      <td>-0.884560</td>\n",
       "      <td>0.720668</td>\n",
       "      <td>0.162410</td>\n",
       "      <td>-0.020973</td>\n",
       "      <td>0.088230</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>0.193849</td>\n",
       "      <td>0.200507</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.610297</td>\n",
       "      <td>-0.426931</td>\n",
       "      <td>-0.583369</td>\n",
       "      <td>-0.477976</td>\n",
       "      <td>-0.300946</td>\n",
       "      <td>-0.476242</td>\n",
       "      <td>-0.357589</td>\n",
       "      <td>-0.122075</td>\n",
       "      <td>-0.962913</td>\n",
       "      <td>-0.646844</td>\n",
       "      <td>-0.484732</td>\n",
       "      <td>-0.483598</td>\n",
       "      <td>-0.352947</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>4.590532</td>\n",
       "      <td>1.164109</td>\n",
       "      <td>0.545269</td>\n",
       "      <td>-0.512737</td>\n",
       "      <td>-0.701965</td>\n",
       "      <td>-0.578150</td>\n",
       "      <td>-0.318117</td>\n",
       "      <td>-0.505985</td>\n",
       "      <td>-0.382594</td>\n",
       "      <td>-0.188536</td>\n",
       "      <td>-0.265335</td>\n",
       "      <td>-0.435466</td>\n",
       "      <td>1.722411</td>\n",
       "      <td>-0.701138</td>\n",
       "      <td>2.017735</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>-0.103382</td>\n",
       "      <td>-0.453930</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.041871</td>\n",
       "      <td>-0.619816</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.967466</td>\n",
       "      <td>-0.212494</td>\n",
       "      <td>-0.543022</td>\n",
       "      <td>-0.408163</td>\n",
       "      <td>-0.576449</td>\n",
       "      <td>0.754388</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.648811</td>\n",
       "      <td>0.228847</td>\n",
       "      <td>-0.499856</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>0.063642</td>\n",
       "      <td>0.370386</td>\n",
       "      <td>0.011318</td>\n",
       "      <td>0.524239</td>\n",
       "      <td>0.214243</td>\n",
       "      <td>9.132035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31430</th>\n",
       "      <td>0.032105</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>1.006746</td>\n",
       "      <td>0.991460</td>\n",
       "      <td>1.329810</td>\n",
       "      <td>1.183829</td>\n",
       "      <td>-0.705908</td>\n",
       "      <td>1.910309</td>\n",
       "      <td>0.533421</td>\n",
       "      <td>0.971720</td>\n",
       "      <td>0.904921</td>\n",
       "      <td>2.125125</td>\n",
       "      <td>2.031338</td>\n",
       "      <td>1.709430</td>\n",
       "      <td>-0.364031</td>\n",
       "      <td>-0.503586</td>\n",
       "      <td>-0.417900</td>\n",
       "      <td>-0.426767</td>\n",
       "      <td>-0.582690</td>\n",
       "      <td>-0.477765</td>\n",
       "      <td>-0.882240</td>\n",
       "      <td>0.098739</td>\n",
       "      <td>1.240635</td>\n",
       "      <td>-0.157351</td>\n",
       "      <td>0.340313</td>\n",
       "      <td>0.246372</td>\n",
       "      <td>-0.646263</td>\n",
       "      <td>-0.485108</td>\n",
       "      <td>-0.896493</td>\n",
       "      <td>-0.953128</td>\n",
       "      <td>-0.213886</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>-0.277840</td>\n",
       "      <td>0.521719</td>\n",
       "      <td>0.339072</td>\n",
       "      <td>0.461273</td>\n",
       "      <td>-0.440225</td>\n",
       "      <td>0.263571</td>\n",
       "      <td>1.691640</td>\n",
       "      <td>1.605189</td>\n",
       "      <td>-0.843717</td>\n",
       "      <td>1.068811</td>\n",
       "      <td>-1.037287</td>\n",
       "      <td>-1.089012</td>\n",
       "      <td>1.054416</td>\n",
       "      <td>1.041294</td>\n",
       "      <td>-0.838111</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>-0.377423</td>\n",
       "      <td>-0.118643</td>\n",
       "      <td>-0.597406</td>\n",
       "      <td>-0.196000</td>\n",
       "      <td>-0.181558</td>\n",
       "      <td>-0.076785</td>\n",
       "      <td>-0.345380</td>\n",
       "      <td>0.187915</td>\n",
       "      <td>0.988782</td>\n",
       "      <td>0.829962</td>\n",
       "      <td>-1.040228</td>\n",
       "      <td>0.236132</td>\n",
       "      <td>0.460198</td>\n",
       "      <td>0.842472</td>\n",
       "      <td>-0.688414</td>\n",
       "      <td>0.242135</td>\n",
       "      <td>0.976359</td>\n",
       "      <td>0.995415</td>\n",
       "      <td>9.272883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89320 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "15569 -1.591570  0.419550  0.409574  0.420952  0.344451  5.268275 -2.638600   \n",
       "39228  1.657266  0.419550  0.429479  0.417079  0.616928 -0.238355 -0.066295   \n",
       "63256  4.420895 -0.874390 -0.864394 -0.873736 -0.139562 -1.085084  0.529977   \n",
       "74827 -1.995347 -1.531313 -1.541189 -1.533136 -0.473125 -0.121628 -0.874190   \n",
       "18477 -0.747015 -0.237373 -0.247316 -0.238324 -0.243295 -3.914652 -1.016323   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204  1.656962 -0.177653 -0.167693 -0.180926  0.821588 -0.252692 -1.339318   \n",
       "88401 -1.596186 -1.531313 -1.541189 -1.534059 -0.700698  0.754291  0.340029   \n",
       "25438 -0.263765  1.116287  1.126180  1.113323  0.730761  0.539529  0.104800   \n",
       "57638  0.083942  0.439457  0.449385  0.443070 -0.884560  0.720668  0.162410   \n",
       "31430  0.032105  0.996846  1.006746  0.991460  1.329810  1.183829 -0.705908   \n",
       "\n",
       "              7         8         9        10        11        12        13  \\\n",
       "15569  0.867947 -0.958219  0.502489 -0.276027  2.705966  1.924548  1.011336   \n",
       "39228  0.398381 -0.351540 -0.109290 -0.039896  0.291888  0.187233  1.412469   \n",
       "63256 -1.422117 -0.051032 -2.512911 -0.879755 -2.558165 -2.110127  0.139685   \n",
       "74827 -1.789493 -1.295655  0.880549 -1.454116 -1.161337 -1.467101  0.818498   \n",
       "18477  0.891080 -0.004867 -1.154787 -0.380911 -0.220514  0.044639  1.258196   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -0.663164 -0.930222 -0.377452 -1.118971 -0.536899 -0.713970  0.579400   \n",
       "88401 -0.000411  0.444887  1.178909  0.504038  0.322184  0.337965  0.814640   \n",
       "25438  0.044383  0.006104 -0.323590  0.044519  0.138877  0.119234  0.367241   \n",
       "57638 -0.020973  0.088230  0.048653  0.193849  0.200507  0.149203  0.610297   \n",
       "31430  1.910309  0.533421  0.971720  0.904921  2.125125  2.031338  1.709430   \n",
       "\n",
       "             14        15        16        17        18        19         20  \\\n",
       "15569  0.296421  0.028303  0.212895 -0.112213 -0.023840 -0.177325  11.163422   \n",
       "39228 -0.426931 -0.530180 -0.477976 -0.426767 -0.556078 -0.477765  -0.016130   \n",
       "63256  2.655177  2.022884  2.465737 -0.112213 -0.236735 -0.177325   0.549805   \n",
       "74827 -0.364031 -0.344019 -0.417900 -0.300946 -0.449630 -0.357589   1.056042   \n",
       "18477  0.233521 -0.024886  0.152820 -0.080758 -0.289959 -0.147281   9.270608   \n",
       "...         ...       ...       ...       ...       ...       ...        ...   \n",
       "61204 -0.426931 -0.583369 -0.477976 -0.426767 -0.502854 -0.477765  -0.358286   \n",
       "88401 -0.364031 -0.503586 -0.417900 -0.363856 -0.502854 -0.417677  -0.369034   \n",
       "25438 -0.426931 -0.583369 -0.477976 -0.332401 -0.423018 -0.387633   0.089186   \n",
       "57638 -0.426931 -0.583369 -0.477976 -0.300946 -0.476242 -0.357589  -0.122075   \n",
       "31430 -0.364031 -0.503586 -0.417900 -0.426767 -0.582690 -0.477765  -0.882240   \n",
       "\n",
       "             21        22        23        24        25        26        27  \\\n",
       "15569  4.744509  6.903074  2.952768  8.991375  6.239567 -0.646263  4.263071   \n",
       "39228  0.131895 -0.646844  0.006340 -0.483598 -0.053288  0.294614 -0.321377   \n",
       "63256  0.436038 -0.646844 -0.975802 -0.895553 -0.952267  2.176367  1.315925   \n",
       "74827  0.699015  0.296893  0.988482  1.164224  2.044331  0.294614  0.497274   \n",
       "18477  1.605086 -0.646844  2.625387  8.167465  5.640248  1.235490  0.988465   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -1.410333 -0.646844 -0.648422 -0.483598 -0.352947 -0.646263  1.152195   \n",
       "88401 -0.256129  1.240635  0.497412  0.752268  0.246372 -0.646263 -0.321377   \n",
       "25438 -0.284689  0.296893  0.170030 -0.483598 -0.652607 -0.646263  0.661004   \n",
       "57638 -0.962913 -0.646844 -0.484732 -0.483598 -0.352947 -0.646263  4.590532   \n",
       "31430  0.098739  1.240635 -0.157351  0.340313  0.246372 -0.646263 -0.485108   \n",
       "\n",
       "             28        29        30        31        32        33        34  \\\n",
       "15569  3.636834  4.441104 -0.481989 -0.671017 -0.547252 -0.311373  0.116526   \n",
       "39228 -0.072252 -0.353769 -0.435937 -0.245459 -0.500976 -0.558643 -0.540297   \n",
       "63256  3.636834  3.242385  2.916167  2.749283  2.867501 -0.275111 -0.054112   \n",
       "74827 -0.484374 -0.653449 -0.514991 -0.218069 -0.580416  0.397065  0.459752   \n",
       "18477  4.048954  2.643026 -0.218305 -0.405615 -0.282281 -0.440242 -0.628870   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -0.484374  0.245590 -0.372290 -0.560603 -0.437018 -0.503760 -0.304361   \n",
       "88401 -0.896493 -0.953128 -0.512976 -0.451153 -0.578391  0.781976  0.815797   \n",
       "25438  0.751989  1.144629 -0.561671 -0.751218 -0.627323 -0.364364 -0.054606   \n",
       "57638  1.164109  0.545269 -0.512737 -0.701965 -0.578150 -0.318117 -0.505985   \n",
       "31430 -0.896493 -0.953128 -0.213886 -0.022234 -0.277840  0.521719  0.339072   \n",
       "\n",
       "             35        36        37        38        39        40        41  \\\n",
       "15569 -0.375818  2.379025 -0.837720 -0.216616 -0.679874 -0.851833  1.441253   \n",
       "39228 -0.624276 -0.862643  0.654132  0.111164  0.818974  0.965010  0.528491   \n",
       "63256 -0.339382 -0.849244 -0.929493 -1.037987 -1.088969  1.041170 -0.351585   \n",
       "74827  0.336021  2.334043  1.455653  1.286623  0.915443 -0.608926  0.542251   \n",
       "18477 -0.505305 -0.839074 -0.628022  1.660188  0.254892  0.679757 -0.805067   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -0.569129 -0.862129 -0.281591  0.564179  1.799167 -0.852391  1.967940   \n",
       "88401  0.722780  1.872242  1.552998  1.338167  0.094505 -0.820758  0.334770   \n",
       "25438 -0.429064  0.852312 -0.000307 -0.783761 -0.962348 -0.808549  1.146843   \n",
       "57638 -0.382594 -0.188536 -0.265335 -0.435466  1.722411 -0.701138  2.017735   \n",
       "31430  0.461273 -0.440225  0.263571  1.691640  1.605189 -0.843717  1.068811   \n",
       "\n",
       "             42        43        44        45        46        47        48  \\\n",
       "15569  0.989817  1.782174 -0.442508  0.300462  0.861421  0.684658  0.862615   \n",
       "39228  0.699632 -0.224033  0.265885 -1.017788  0.448340  1.252381  0.670103   \n",
       "63256  1.247452  1.485541 -1.979334 -1.862797  0.552265  0.652249  0.385049   \n",
       "74827 -1.002200 -1.071539  0.751532  0.143673  0.264638  0.355586 -0.172777   \n",
       "18477  0.074232 -0.535480  1.281962 -1.043885  0.638068  1.469045  0.847498   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -0.377056  0.605589 -0.437310 -1.181482 -2.303588  0.811427 -0.718607   \n",
       "88401 -1.033856 -1.087304  1.254948  0.698499 -0.060818 -0.205245  0.271961   \n",
       "25438  0.613324  1.483805 -0.795387  0.193299 -0.091760 -0.472319  0.051091   \n",
       "57638  0.941904 -0.103382 -0.453930  0.845504  0.041871 -0.619816  0.818792   \n",
       "31430 -1.037287 -1.089012  1.054416  1.041294 -0.838111 -0.005948 -0.377423   \n",
       "\n",
       "             49        50        51        52        53        54        55  \\\n",
       "15569  0.855227  6.053265  1.163374  3.210753  2.555351  0.597081  1.156251   \n",
       "39228  0.576805 -0.035673 -0.541829 -0.365109 -0.633775  1.312632 -0.010459   \n",
       "63256  0.546543  1.729638  0.092868  1.128907  1.094857 -2.484805 -0.933589   \n",
       "74827 -0.069807  1.238364  0.053652  0.684905  0.499513  1.283343  0.106117   \n",
       "18477  1.118936  4.856749  1.770205  0.944526  1.041571 -1.251713  5.038597   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204  0.095167 -0.690082  0.467158 -0.412690 -0.138718 -0.112264 -0.579451   \n",
       "88401  0.435646  0.148935 -0.428325 -0.130954 -0.246770  1.124562  0.069795   \n",
       "25438  0.148756  0.015568 -0.390475 -0.003853 -0.170826 -0.825931 -0.023933   \n",
       "57638  0.967466 -0.212494 -0.543022 -0.408163 -0.576449  0.754388  0.002508   \n",
       "31430 -0.118643 -0.597406 -0.196000 -0.181558 -0.076785 -0.345380  0.187915   \n",
       "\n",
       "             56        57        58        59        60        61        62  \\\n",
       "15569  3.101378  2.763801  0.000220  1.877375  1.067262  1.468370  0.454987   \n",
       "39228  0.497131  0.078190 -0.438461  0.006160  0.311147  0.217054  0.820794   \n",
       "63256 -4.515653 -3.661379 -2.859678 -0.459531 -2.769091 -2.158519 -3.062226   \n",
       "74827  0.730878  0.419319  2.151723  0.917287  1.351149  1.647902  1.857436   \n",
       "18477  0.616455  2.376650  2.432383 -0.368392 -0.208555 -0.441813  0.040802   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61204 -0.254788 -0.345010 -2.358189 -1.635336 -1.687696 -1.528272 -1.049639   \n",
       "88401  0.952169  0.604934  1.627698  0.158657  1.523564  0.916127  1.522226   \n",
       "25438 -0.121071 -0.086152 -0.299082  0.685928  0.652316  0.825749 -0.751525   \n",
       "57638  0.648811  0.228847 -0.499856  0.027273 -0.011168  0.063642  0.370386   \n",
       "31430  0.988782  0.829962 -1.040228  0.236132  0.460198  0.842472 -0.688414   \n",
       "\n",
       "             63        64        65     TARGET  \n",
       "15569  1.632157  2.922553  2.837309 -10.046572  \n",
       "39228 -0.007006  0.520544  0.142942  -9.546656  \n",
       "63256 -0.963747 -4.707058 -3.834919  -9.106747  \n",
       "74827  0.399532  1.097568  0.939363  -8.929755  \n",
       "18477  4.246476  0.424501  1.831210  -8.914202  \n",
       "...         ...       ...       ...        ...  \n",
       "61204 -1.050762 -0.834965 -0.834457   8.679049  \n",
       "88401  0.113719  1.341889  0.833395   8.772971  \n",
       "25438  0.209183  0.143924  0.222764   8.879313  \n",
       "57638  0.011318  0.524239  0.214243   9.132035  \n",
       "31430  0.242135  0.976359  0.995415   9.272883  \n",
       "\n",
       "[89320 rows x 67 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_remove_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53e5b637-07be-4ee7-adec-02f528429396",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "train_remove_std = train_remove_std.sort_values(by=['TARGET'])\n",
    "for i in range(train_remove_std.shape[0]):\n",
    "    if train_remove_std.iloc[i, 66] < 0 and train_remove_std.iloc[i+1, 66] > 0:\n",
    "        index = i\n",
    "        break\n",
    "samples = train_remove_std.iloc[index-1000:index+1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e90eb95-282e-415e-a6bb-81d93114b95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape: (1600, 66)\n",
      "Validation X shape: (400, 66)\n",
      "Train Y shape: (1600, 1)\n",
      "Val Y shape: (400, 1)\n",
      "train_max: 153.0990565158\n",
      "val_max: 38.75009866110001\n",
      "test_max: 55.96225182400002\n"
     ]
    }
   ],
   "source": [
    "input_features = samples.drop(['TARGET'], axis=1).to_numpy()\n",
    "output_features = pd.DataFrame((np.sign(samples['TARGET'])+1)//2).to_numpy()\n",
    "\n",
    "X_test = test_std.drop(['TARGET'], axis=1).to_numpy()\n",
    "Y_test = pd.DataFrame((np.sign(test_std['TARGET'])+1)//2).to_numpy()\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(input_features, output_features, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, val_data = train_test_split(train_remove, test_size=0.2, random_state=42)\n",
    "test_data = test\n",
    "\n",
    "auto_train_max = np.sum(train_data['TARGET'][train_data['TARGET']>0])\n",
    "auto_val_max = np.sum(val_data['TARGET'][val_data['TARGET']>0])\n",
    "auto_test_max = np.sum(test['TARGET'][test['TARGET']>0])\n",
    "\n",
    "print('Train X shape:', X_train.shape)\n",
    "print('Validation X shape:', X_val.shape)\n",
    "print('Train Y shape:', Y_train.shape)\n",
    "print('Val Y shape:', Y_val.shape)\n",
    "print('train_max:', auto_train_max)\n",
    "print('val_max:', auto_val_max)\n",
    "print('test_max:', auto_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "126ae12d-ead9-4a7d-848d-abb0ee2c4854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71456, 66)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all = train_data.drop(['TARGET'], axis=1).to_numpy()\n",
    "train_data_all_label = pd.DataFrame((np.sign(train_data['TARGET'])+1)//2).to_numpy()\n",
    "train_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f7a19ea-d496-4ee3-b66d-7f33a40361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.from_numpy(X_train)\n",
    "train_output = torch.from_numpy(Y_train)\n",
    "val_input = torch.from_numpy(X_val)\n",
    "val_output = torch.from_numpy(Y_val)\n",
    "test_input = torch.from_numpy(X_test)\n",
    "test_output = torch.from_numpy(Y_test)\n",
    "\n",
    "train_data_all = torch.from_numpy(train_data_all)\n",
    "train_data_all_label = torch.from_numpy(train_data_all_label)\n",
    "\n",
    "train_input = train_input.float()\n",
    "train_output = train_output.float()\n",
    "val_input = val_input.float()\n",
    "val_output = val_output.float()\n",
    "test_input = test_input.float()\n",
    "test_output = test_output.float()\n",
    "\n",
    "train_data_all = train_data_all.float()\n",
    "train_data_all_label = train_data_all_label.float()\n",
    "\n",
    "input_feature = train_input.shape[1]\n",
    "output_feature = 1\n",
    "\n",
    "# print('input_feature:', input_feature)\n",
    "# print('output_feature:', output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc51d674-8c1a-41e0-84ef-090bde3fed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5905984-75d6-422d-9f95-98666a7d22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.to(device)\n",
    "train_output = train_output.to(device)\n",
    "val_input = val_input.to(device)\n",
    "val_output = val_output.to(device)\n",
    "test_input = test_input.to(device)\n",
    "test_output = test_output.to(device)\n",
    "\n",
    "train_data_all = train_data_all.to(device)\n",
    "train_data_all_label = train_data_all_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "852276a1-d972-4d87-8724-e9c1c973513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9a0344a-7b96-48ff-852a-999ea40a6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-encoder model\n",
    "# base model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_feature, input_feature//2)\n",
    "        self.linear2 = nn.Linear(input_feature//2, input_feature//4)\n",
    "        self.linear3 = nn.Linear(input_feature//4, input_feature//16)\n",
    "        self.linear4 = nn.Linear(input_feature//16, input_feature//16)\n",
    "        \n",
    "        self.linear5 = nn.Linear(input_feature//16, input_feature//16)\n",
    "        self.linear6 = nn.Linear(input_feature//16+input_feature, input_feature//16)\n",
    "        \n",
    "        self.batchnorm_1 = nn.BatchNorm1d(input_feature//2)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(input_feature//4)\n",
    "        self.batchnorm_3 = nn.BatchNorm1d(input_feature//16)\n",
    "        self.linear = nn.Linear(input_feature//16, 1)\n",
    "        \n",
    "        nn.init.constant_(self.linear1.weight, 0.1)\n",
    "        nn.init.constant_(self.linear2.weight, 0.1)\n",
    "        nn.init.constant_(self.linear3.weight, 0.1)\n",
    "        nn.init.constant_(self.linear4.weight, 0.1)\n",
    "        nn.init.constant_(self.linear.weight, 0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "#         self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, x_):\n",
    "        x = self.linear1(x_)\n",
    "#         x = self.batchnorm_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "#         x = self.batchnorm_2(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "#         x = self.batchnorm_3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.linear4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.linear5(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = torch.cat((x, x_), 1)\n",
    "        x = self.linear6(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        output = self.linear(x)\n",
    "                \n",
    "        return output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dbcb1-6bea-4789-937e-d4e35d145de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # auto-encoder model\n",
    "# # base model\n",
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 2)\n",
    "#         self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "#         self.linear = nn.Linear(128, 1)\n",
    "        \n",
    "#         self.linear2 = nn.Linear(input_feature//2, input_feature//4)\n",
    "#         self.linear3 = nn.Linear(input_feature//4, input_feature//16)\n",
    "#         self.linear4 = nn.Linear(input_feature//16, input_feature//16)\n",
    "        \n",
    "#         self.linear5 = nn.Linear(input_feature//16, input_feature//16)\n",
    "#         self.linear6 = nn.Linear(input_feature//16+input_feature, input_feature//16)\n",
    "        \n",
    "#         self.batchnorm_1 = nn.BatchNorm1d(input_feature//2)\n",
    "#         self.batchnorm_2 = nn.BatchNorm1d(input_feature//4)\n",
    "#         self.batchnorm_3 = nn.BatchNorm1d(input_feature//16)\n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.15)\n",
    "        \n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "#     def forward(self, x_):\n",
    "#         x = self.conv1(x_)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.relu(x)\n",
    "#         output = self.linear(x)\n",
    "#         return output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "22bb31c5-cbce-4611-ab4a-3f33902bdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000\n",
    "train_ds = TensorDataset(train_input, train_output)\n",
    "train_dl = DataLoader(train_ds, batch_size= batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed2d7429-de64-4f06-8610-93c27155281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def fit(num_epochs, model, loss_fn, train_input, train_output, val_input, val_output, test_input, test_output, model_path):\n",
    "    best_loss = float('inf')\n",
    "    train_pred_output = []\n",
    "    val_pred_output = []\n",
    "    train_error = []\n",
    "    val_error = []\n",
    "    test_error = []\n",
    "    epochs = []\n",
    "    \n",
    "    train_returns = []\n",
    "    val_returns = []\n",
    "    test_returns = []\n",
    "    \n",
    "    train_sum = []\n",
    "    val_sum = []\n",
    "    test_sum = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for x,y in train_dl:\n",
    "            model = model.train()\n",
    "            opt.zero_grad()\n",
    "            pred = model(x)\n",
    "#             loss = loss_fn(pred, y.long().squeeze())\n",
    "            y = torch.reshape(y, (y.shape[0], 1))\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(loss)\n",
    "            model = model.eval()\n",
    "            \n",
    "            train_pred = model(train_data_all)\n",
    "            train_pred_index = torch.argmax(train_pred, dim=1)\n",
    "            train_output = torch.reshape(train_output, (train_output.shape[0], 1))\n",
    "#             train_loss = loss_fn(train_output, train_pred)\n",
    "#             train_loss = loss_fn(train_pred, train_data_all_label.long().squeeze())\n",
    "            train_loss = loss_fn(train_output, train_pred)\n",
    "            train_loss = train_loss.cpu().detach().numpy()\n",
    "\n",
    "            test_pred = model(test_input)\n",
    "            test_pred_index = torch.argmax(test_pred, dim=1)\n",
    "            test_output = torch.reshape(test_output, (test_output.shape[0], 1))\n",
    "#             val_loss = loss_fn(val_output, val_pred)\n",
    "#             test_loss = loss_fn(test_pred, test_output.long().squeeze())\n",
    "            test_loss = loss_fn(test_output, test_pred)\n",
    "            test_loss = test_loss.cpu().detach().numpy()\n",
    "    \n",
    "            epochs.append(epoch)\n",
    "            train_error.append(math.log(train_loss+1))\n",
    "            test_error.append(math.log(test_loss+1))\n",
    "            \n",
    "#             figure, ax = plt.subplots(1, 2, figsize = (20, 7))\n",
    "#             ax = ax.flatten()\n",
    "            \n",
    "#             figure, ax = plt.subplots(1, 4, figsize = (22, 5))\n",
    "#             ax = ax.flatten()\n",
    "            \n",
    "#             plt.grid(False)\n",
    "#             train_conf = confusion_matrix(train_output, train_pred_index)\n",
    "#             g1 = sns.heatmap(train_conf, cmap=\"YlGnBu\",cbar=False, ax=ax[0], annot = True)\n",
    "#             g1.set_ylabel('True Target')\n",
    "#             g1.set_xlabel('Predict Target')\n",
    "#             g1.set_title('Train dataset')\n",
    "\n",
    "#             plt.grid(False)\n",
    "#             val_conf = confusion_matrix(val_output, val_pred_index)\n",
    "#             g2 = sns.heatmap(val_conf, cmap=\"YlGnBu\",cbar=False, ax=ax[1], annot = True)\n",
    "#             g2.set_ylabel('True Target')\n",
    "#             g2.set_xlabel('Predict Target')\n",
    "#             g2.set_title('Val dataset')\n",
    "            \n",
    "#             plt.grid(False)\n",
    "#             test_conf = confusion_matrix(test_output, test_pred_index)\n",
    "#             g3 = sns.heatmap(test_conf, cmap=\"YlGnBu\",cbar=False, ax=ax[2], annot = True)\n",
    "#             g3.set_ylabel('True Target')\n",
    "#             g3.set_xlabel('Predict Target')\n",
    "#             g3.set_title('Test dataset')\n",
    "            \n",
    "            train_pred_np = train_pred_index.cpu().detach().numpy()\n",
    "            train_output_np = train_output.cpu().detach().numpy()\n",
    "            test_pred_np = test_pred_index.cpu().detach().numpy()\n",
    "            test_output_np = test_output.cpu().detach().numpy()\n",
    "            \n",
    "#             train_max_value = max(max(train_output_np), max(train_pred_np))\n",
    "#             train_min_value = min(min(train_output_np), min(train_pred_np))\n",
    "#             val_max_value = max(max(val_output_np), max(val_pred_np))\n",
    "#             val_min_value = min(min(val_output_np), min(val_pred_np))\n",
    "#             test_max_value = max(max(test_output_np), max(test_pred_np))\n",
    "#             test_min_value = min(min(test_output_np), min(test_pred_np))\n",
    "            \n",
    "#             ax[0].scatter(train_output_np, train_pred_np, s = 20, alpha=0.3, c='blue')\n",
    "#             ax[1].scatter(val_output_np, val_pred_np, s = 20, alpha=0.3, c='red')\n",
    "#             ax[2].scatter(test_output_np, test_pred_np, s = 20, alpha=0.3, c='green')\n",
    "            \n",
    "#             ax[0].plot(epochs, train_error, c='blue')\n",
    "#             ax[0].plot(epochs, val_error, c='red')\n",
    "#             ax[0].plot(epochs, test_error, c='green')\n",
    "#             ax[0].set_title('Errors vs Epochs', fontsize=15)\n",
    "#             ax[0].set_xlabel('Epoch', fontsize=10)\n",
    "#             ax[0].set_ylabel('Errors', fontsize=10)\n",
    "\n",
    "#             ax[0].legend(['train', 'valid', 'test'])\n",
    "            \n",
    "#             ax[0].set_xlim([train_min_value, train_max_value])\n",
    "#             ax[0].set_ylim([train_min_value, train_max_value])\n",
    "#             ax[0].set_title('Trainig data', fontsize=15)\n",
    "#             ax[0].set_xlabel('Target', fontsize=10)\n",
    "#             ax[0].set_ylabel('Prediction', fontsize=10)\n",
    "#             ax[0].plot([train_min_value, train_max_value], [train_min_value, train_max_value], 'k-')\n",
    "            \n",
    "#             ax[1].set_xlim([val_min_value, val_max_value])\n",
    "#             ax[1].set_ylim([val_min_value, val_max_value])\n",
    "#             ax[1].set_title('Validation data', fontsize=15)\n",
    "#             ax[1].set_xlabel('Target', fontsize=10)\n",
    "#             ax[1].set_ylabel('Prediction', fontsize=10)\n",
    "#             ax[1].plot([val_min_value, val_max_value], [val_min_value, val_max_value], 'k-')\n",
    "            \n",
    "#             ax[2].set_xlim([test_min_value, test_max_value])\n",
    "#             ax[2].set_ylim([test_min_value, test_max_value])\n",
    "#             ax[2].set_title('Testing data', fontsize=15)\n",
    "#             ax[2].set_xlabel('Target', fontsize=10)\n",
    "#             ax[2].set_ylabel('Prediction', fontsize=10)\n",
    "#             ax[2].plot([test_min_value, test_max_value], [test_min_value, test_max_value], 'k-')\n",
    "            \n",
    "#             ax[3].plot(epochs, train_error, c='blue')\n",
    "#             ax[3].plot(epochs, val_error, c='red')\n",
    "#             ax[3].plot(epochs, test_error, c='green')\n",
    "#             ax[3].set_title('Training and Validation error', fontsize=15)\n",
    "#             ax[3].set_xlabel('Epochs', fontsize=10)\n",
    "#             ax[3].set_ylabel('MSE error', fontsize=10)\n",
    "            \n",
    "#             display.clear_output(wait=True)\n",
    "#             display.display(pl.gcf())\n",
    "            \n",
    "#             print('Epoch ', epoch, 'Train_loss: ', train_loss*1000, ' Validation_loss: ', val_loss*100, ' Test_loss: ', test_loss*100)\n",
    "            \n",
    "            train_res = np.sum(train_data['TARGET'][train_pred_np>0])\n",
    "            test_res = np.sum(test_data['TARGET'][test_pred_np>0])\n",
    "            \n",
    "#             train_returns.append(train_res)\n",
    "#             val_returns.append(val_res)\n",
    "#             test_returns.append(test_res)\n",
    "            \n",
    "#             ax[1].plot(epochs, train_returns, c='blu`e')\n",
    "#             ax[1].plot(epochs, val_returns, c='red')\n",
    "#             ax[1].plot(epochs, test_returns, c='green')\n",
    "#             ax[1].legend(['train', 'valid', 'test'])\n",
    "#             ax[1].set_title('Return vs Epochs', fontsize=15)\n",
    "#             ax[1].set_xlabel('Epoch', fontsize=10)\n",
    "#             ax[1].set_ylabel('Returns', fontsize=10)\n",
    "\n",
    "#             display.clear_output(wait=True)\n",
    "#             display.display(pl.gcf())\n",
    "            \n",
    "            train_sum.append(train_res)\n",
    "            test_sum.append(test_res)\n",
    "            \n",
    "#             print(f'Maximum sum train return {train_res}, Total train return: {auto_train_max}, Maximum train percentage return: {train_res/auto_train_max*100}%')\n",
    "#             print(f'Maximum sum train return {val_res}, Total train return: {auto_val_max}, Maximum train percentage return: {val_res/auto_val_max*100}%')\n",
    "#             print(f'Maximum sum test return {test_res}, Total test return: {auto_test_max}, Maximum test percentage return: {test_res/auto_test_max*100}%')\n",
    "#             print('Epoch:', epoch, 'Train loss:', train_loss, 'Val loss:', val_loss, 'Test loss:', test_loss)\n",
    "            print(f'Epoch: {epoch}, Train loss: {train_loss}, Train return: {train_res/auto_train_max*100}%, Test loss: {test_loss}, Test return: {test_res/auto_test_max*100}%')\n",
    "        \n",
    "                \n",
    "#             train_pred_output.append([train_pred.cpu().detach().numpy(), train_output.cpu().detach().numpy()])\n",
    "#             val_pred_output.append([val_pred.cpu().detach().numpy(), val_output.cpu().detach().numpy()])\n",
    "    return train_sum, test_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "966e1596-f5a6-4719-8056-f538126e72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 0, Train loss: 39.5519905090332, Train return: 0.0%, Test loss: 0.6932872533798218, Test return: 0.0%\n",
      "tensor(0.6797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 500, Train loss: 109093.453125, Train return: 0.02719656407268776%, Test loss: 0.7063970565795898, Test return: -3.820809460142211%\n",
      "tensor(0.6582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 1000, Train loss: 121394.328125, Train return: -0.23326950154205786%, Test loss: 0.7485681176185608, Test return: -2.7636133493411927%\n",
      "tensor(0.6428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 1500, Train loss: 112280.109375, Train return: -0.7889288474324135%, Test loss: 0.787286639213562, Test return: -4.019260811866385%\n",
      "tensor(0.6243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 2000, Train loss: 211319.4375, Train return: -0.29901121843475%, Test loss: 0.8352581858634949, Test return: -4.110985998625195%\n",
      "tensor(0.6113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 2500, Train loss: 267224.8125, Train return: -0.6999462862068052%, Test loss: 0.8852616548538208, Test return: -3.636523859690806%\n",
      "tensor(0.6017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 3000, Train loss: 381687.1875, Train return: 0.029775554688212857%, Test loss: 0.9165802597999573, Test return: -4.389276008272728%\n",
      "tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 3500, Train loss: 542551.5, Train return: 0.04220373055880449%, Test loss: 0.9424123167991638, Test return: -3.8660319867117128%\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 4000, Train loss: 709394.6875, Train return: -0.12470250068477523%, Test loss: 0.9677630662918091, Test return: -3.8286666747050364%\n",
      "tensor(0.5842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 4500, Train loss: 850450.9375, Train return: -0.015285940705705712%, Test loss: 0.9871398210525513, Test return: -3.7900006162554254%\n",
      "tensor(0.5802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 5000, Train loss: 992910.375, Train return: -0.11081540465436586%, Test loss: 0.9980382323265076, Test return: -4.103000680210797%\n",
      "tensor(0.5751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 5500, Train loss: 1106936.5, Train return: -0.04167198312774437%, Test loss: 1.007975459098816, Test return: -3.966201193941433%\n",
      "tensor(0.5686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 6000, Train loss: 1214284.5, Train return: -0.012669672460063916%, Test loss: 1.0262467861175537, Test return: -3.8610799147173345%\n",
      "tensor(0.5586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 6500, Train loss: 1302825.875, Train return: -0.01017751144559924%, Test loss: 1.0480927228927612, Test return: -4.223411092236249%\n",
      "tensor(0.5480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 7000, Train loss: 1432787.375, Train return: 0.025133707467380043%, Test loss: 1.0981335639953613, Test return: -4.494233346631313%\n",
      "tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 7500, Train loss: 1578476.625, Train return: 0.01863180717711097%, Test loss: 1.1385889053344727, Test return: -4.200835746198115%\n",
      "tensor(0.5312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 8000, Train loss: 1707681.625, Train return: 0.0%, Test loss: 1.1876072883605957, Test return: -3.8834958854674966%\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 8500, Train loss: 1829288.375, Train return: 0.0%, Test loss: 1.2308285236358643, Test return: -3.9701180466922974%\n",
      "tensor(0.5209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 9000, Train loss: 1897298.625, Train return: 0.0%, Test loss: 1.272130012512207, Test return: -3.986196857867191%\n",
      "tensor(0.5159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 9500, Train loss: 2028464.0, Train return: 0.0%, Test loss: 1.3317543268203735, Test return: -4.288541996751369%\n",
      "tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 10000, Train loss: 2028013.875, Train return: 0.0%, Test loss: 1.3724445104599, Test return: -4.169472011487796%\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 10500, Train loss: 2052558.875, Train return: 0.0%, Test loss: 1.400131106376648, Test return: -4.105417748423588%\n",
      "tensor(0.5103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 11000, Train loss: 2057443.0, Train return: 0.0%, Test loss: 1.4323004484176636, Test return: -3.8473833014643404%\n",
      "tensor(0.5074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 11500, Train loss: 2086138.125, Train return: 0.0%, Test loss: 1.470182180404663, Test return: -3.779706737770841%\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 12000, Train loss: 2125197.25, Train return: 0.0%, Test loss: 1.549725890159607, Test return: -3.290077787774759%\n",
      "tensor(0.4959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 12500, Train loss: 2118796.0, Train return: 0.0%, Test loss: 1.613626480102539, Test return: -3.28798777716604%\n",
      "tensor(0.4898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 13000, Train loss: 2180532.0, Train return: 0.0%, Test loss: 1.7267820835113525, Test return: -3.8374154859848213%\n",
      "tensor(0.4888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 13500, Train loss: 2207548.25, Train return: 0.0%, Test loss: 1.7894773483276367, Test return: -4.135725894445557%\n",
      "tensor(0.4856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 14000, Train loss: 2279695.25, Train return: 0.0%, Test loss: 1.8736000061035156, Test return: -3.4907758929068207%\n",
      "tensor(0.4867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 14500, Train loss: 2339449.0, Train return: 0.0%, Test loss: 1.942432165145874, Test return: -3.7412481852670902%\n",
      "tensor(0.4821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 15000, Train loss: 2464466.25, Train return: 0.0%, Test loss: 1.9885464906692505, Test return: -3.5640879146049986%\n",
      "tensor(0.4804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 15500, Train loss: 2556681.75, Train return: 0.0%, Test loss: 2.0574843883514404, Test return: -3.3296661679380093%\n",
      "tensor(0.4784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 16000, Train loss: 2620242.25, Train return: 0.0%, Test loss: 2.0889177322387695, Test return: -3.584963239344862%\n",
      "tensor(0.4777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 16500, Train loss: 2641646.25, Train return: 0.0%, Test loss: 2.1763787269592285, Test return: -3.021315534474049%\n",
      "tensor(0.4784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 17000, Train loss: 2659683.75, Train return: 0.0007755900180073658%, Test loss: 2.2116565704345703, Test return: -3.512871565609356%\n",
      "tensor(0.4772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 17500, Train loss: 2718880.0, Train return: 0.0007755900180073658%, Test loss: 2.242014169692993, Test return: -3.3553837463608045%\n",
      "tensor(0.4759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 18000, Train loss: 2738998.25, Train return: 0.0007755900180073658%, Test loss: 2.278398275375366, Test return: -3.6782867802993073%\n",
      "tensor(0.4730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 18500, Train loss: 2754788.75, Train return: 0.0007755900180073658%, Test loss: 2.297157049179077, Test return: -3.2453994069286245%\n",
      "tensor(0.4726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 19000, Train loss: 2741300.5, Train return: 0.0018073311899962242%, Test loss: 2.3222389221191406, Test return: -3.651412690158512%\n",
      "tensor(0.4764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch: 19500, Train loss: 2752184.0, Train return: 0.0011093020679880745%, Test loss: 2.3470237255096436, Test return: -3.730989116318156%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20000\n",
    "learning_rate = 0.01\n",
    "loss_fn = F.mse_loss\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "model = Autoencoder()\n",
    "model = model.to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "train_sum_1, test_sum_1 = fit(num_epochs, model, loss_fn, train_input, train_output, val_input, val_output, test_input, test_output, 'model_path_1')\n",
    "# fig.savefig(\"auto_encoder.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de8fa4-22a4-42a9-83f7-c7a3bb94972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Autoencoder_model()\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Single_cell_competition",
   "language": "python",
   "name": "single_cell_competition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
